{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "res_folders=os.listdir('../../results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(0)# str(hvd.local_rank())\n",
    "keras.backend.set_session(tf.Session(config=config))\n",
    "verbose=1 \n",
    "init=tf.global_variables_initializer() #initialize_all_variables()\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder='/home/mara/multitask_adversarial/results/STANDARD_FCONTRAST_2409/'\n",
    "CONCEPT=['full_contrast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../doc/data_shuffle.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../../doc/data_shuffle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder=model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using brightness standardization\n",
      "data generators created\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RUN SEQUENTIAL\n",
    "python hvd_train_unc.py SEED EXPERIMENT_TYPE \n",
    "\"\"\"\n",
    "BATCH_SIZE=32\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "from keras import *\n",
    "import setproctitle\n",
    "SERVER_NAME = 'ultrafast'\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "sys.path.append('../../lib/TASK_2_UC1/')\n",
    "from models import *\n",
    "from util import otsu_thresholding\n",
    "from extract_xml import *\n",
    "from functions import *                   \n",
    "sys.path.append('../../lib/')\n",
    "from mlta import *\n",
    "import math\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "cam16 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/cam16_500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "all500 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/all500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "extra17 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/extra17/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "tumor_extra17=hd.File('/home/mara/adversarialMICCAI/data/ultrafast/1129-1155/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "test2 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/test_data2/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "pannuke= hd.File('/home/mara/adversarialMICCAI/data/ultrafast/pannuke/patches_fix.h5py', 'r', libver='latest', swmr=True)\n",
    "global data\n",
    "data={'cam16':cam16,'all500':all500,'extra17':extra17, 'tumor_extra17':tumor_extra17, 'test_data2': test2, 'pannuke':pannuke}\n",
    "global concept_db\n",
    "concept_db = hd.File('../../data/normalized_cmeasures/concept_values_def.h5py','r', libver='latest', swmr=True)\n",
    "\n",
    "\n",
    "# DATA SPLIT CSVs \n",
    "train_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/train_shuffle.csv', 'r') # How is the encoding of .csv files ?\n",
    "val_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/val_shuffle.csv', 'r')\n",
    "test_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/test_shuffle.csv', 'r')\n",
    "train_list=train_csv.readlines()\n",
    "val_list=val_csv.readlines()\n",
    "test_list=test_csv.readlines()\n",
    "test2_csv = open('/mnt/nas2/results/IntermediateResults/Camelyon/test2_shuffle.csv', 'r')\n",
    "test2_list=test2_csv.readlines()\n",
    "test2_csv.close()\n",
    "train_csv.close()\n",
    "val_csv.close()\n",
    "test_csv.close()\n",
    "data_csv=open('../../doc/data_shuffle.csv', 'r')\n",
    "data_list=data_csv.readlines()\n",
    "data_csv.close()\n",
    "\n",
    "\n",
    "# STAIN NORMALIZATION\n",
    "def get_normalizer(patch, save_folder=''):\n",
    "    normalizer = ReinhardNormalizer()\n",
    "    normalizer.fit(patch)\n",
    "    np.save('{}/normalizer'.format(save_folder),normalizer)\n",
    "    np.save('{}/normalizing_patch'.format(save_folder), patch)\n",
    "    #print('Normalisers saved to disk.')\n",
    "    return normalizer\n",
    "def normalize_patch(patch, normalizer):\n",
    "    return np.float64(normalizer.transform(np.uint8(patch)))\n",
    "\n",
    "# LOAD DATA NORMALIZER\n",
    "global normalizer\n",
    "db_name, entry_path, patch_no = get_keys(data_list[0])\n",
    "normalization_reference_patch = data[db_name][entry_path][patch_no]\n",
    "normalizer = get_normalizer(normalization_reference_patch, save_folder=new_folder)\n",
    "\n",
    "\"\"\"\n",
    "Batch generators: \n",
    "They load a patch list: a list of file names and paths. \n",
    "They use the list to create a batch of 32 samples. \n",
    "\"\"\"\n",
    "\n",
    "# Retrieve Concept Measures\n",
    "def get_concept_measure(db_name, entry_path, patch_no, measure_type=''):\n",
    "    if measure_type=='domain':\n",
    "        return get_domain(db_name, entry_path)\n",
    "    path=db_name+'/'+entry_path+'/'+str(patch_no)+'/'+measure_type.strip(' ')\n",
    "    try:\n",
    "        cm=concept_db[path][0]\n",
    "        return cm\n",
    "    except:\n",
    "        print(\"[ERR]: {}, {}, {}, {} with path {}\".format(db_name, entry_path, patch_no, measure_type, path))\n",
    "        return 1.\n",
    "    \n",
    "\n",
    "# BATCH GENERATORS\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, patch_list, concept=CONCEPT, batch_size=32, shuffle=True, data_type=0):\n",
    "        self.batch_size=batch_size\n",
    "        self.patch_list=patch_list\n",
    "        self.shuffle=shuffle\n",
    "        self.concept = concept\n",
    "        self.data_type=data_type\n",
    "        #print 'data type:', data_type\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.patch_list)/self.batch_size))\n",
    "    def __getitem__(self, index):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        indexes=self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        patch_list_temp=[self.patch_list[k] for k in indexes]\n",
    "        self.patch_list_temp=patch_list_temp\n",
    "        return self.__data_generation(self)\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.patch_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def __data_generation(self, patch_list_temp):\n",
    "        patch_list_temp=self.patch_list_temp\n",
    "        batch_x=np.zeros((len(patch_list_temp), 224,224,3))\n",
    "        batch_y=np.zeros(len(patch_list_temp))\n",
    "        i=0\n",
    "        for line in patch_list_temp:\n",
    "            db_name, entry_path, patch_no = get_keys(line)\n",
    "            patch=data[db_name][entry_path][patch_no]\n",
    "            patch=normalize_patch(patch, normalizer)\n",
    "            patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "            label = get_class(line, entry_path) \n",
    "            if self.data_type!=0:\n",
    "                label=get_test_label(entry_path)\n",
    "            batch_x[i]=patch\n",
    "            batch_y[i]=label\n",
    "            i+=1\n",
    "        generator_output=[batch_y]\n",
    "        for c in self.concept:\n",
    "            batch_concept_values=np.zeros(len(patch_list_temp))\n",
    "            i=0\n",
    "            for line in patch_list_temp:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                batch_concept_values[i]=get_concept_measure(db_name, entry_path, patch_no, measure_type=c)\n",
    "                i+=1\n",
    "            if c=='domain':\n",
    "                    batch_concept_values=keras.utils.to_categorical(batch_concept_values, num_classes=7)\n",
    "            generator_output.append(batch_concept_values)\n",
    "        return batch_x, generator_output # batch_x, np.asarray(batch_y), generator_output[1], generator_output[2]\n",
    "\n",
    "\"\"\"\n",
    "Credits for the Gradient Reversal Layer\n",
    "https://github.com/michetonu/gradient_reversal_keras_tf/blob/master/flipGradientTF.py\n",
    "\"\"\"\n",
    "def reverse_gradient(X, hp_lambda):\n",
    "    '''Flips the sign of the incoming gradient during training.'''\n",
    "    hp_lambda = hp_lambda\n",
    "    try:\n",
    "        reverse_gradient.num_calls += 1\n",
    "    except AttributeError:\n",
    "        reverse_gradient.num_calls = 1\n",
    "    grad_name = \"GradientReversal%d\" % reverse_gradient.num_calls\n",
    "    @tf.RegisterGradient(grad_name)\n",
    "    def _flip_gradients(op, grad):\n",
    "        grad = tf.negative(grad)\n",
    "        #grad = tf.Print(grad, [grad], 'grad')\n",
    "        final_val = grad * hp_lambda \n",
    "        #final_val =tf.Print(final_val, [final_val], 'final_val')\n",
    "        return [final_val]\n",
    "    g = keras.backend.get_session().graph\n",
    "    with g.gradient_override_map({'Identity': grad_name}):\n",
    "        y = tf.identity(X)\n",
    "    return y\n",
    "\n",
    "class Hp_lambda():\n",
    "    def __init__(self,in_val):\n",
    "        self.value=in_val\n",
    "    def update(self,new_val):\n",
    "        self.value=new_val\n",
    "    def get_hyperparameter_lambda(self):\n",
    "        #val = tf.Print(self.value,[self.value],'hplambda: ')\n",
    "        return tf.Variable(self.value, name='hp_lambda')\n",
    "    #return lmb\n",
    "class GradientReversal(Layer):\n",
    "    '''Flip the sign of gradient during training.'''\n",
    "    def __init__(self, hp_lambda, **kwargs):\n",
    "        super(GradientReversal, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "        self.hp_lambda = Hp_lambda(hp_lambda)\n",
    "        #self.hp_lambda = tf.Variable(hp_lambda, name='hp_lambda')\n",
    "        #self.hp_lambda = tf.Variable(hp_lambda, name='hp_lambda')\n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "        return\n",
    "    def call(self, x, mask=None):\n",
    "        #tf.Print(self.hp_lambda, [self.hp_lambda],'self.hp_lambda: ')\n",
    "        #with tf.Session() as sess:  print(self.hp_lambda.eval()) \n",
    "        lmb=self.hp_lambda.get_hyperparameter_lambda()\n",
    "        return reverse_gradient(x, lmb)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__,\n",
    "                  'hp_lambda': keras.backend.get_value(self.hp_lambda)}\n",
    "        base_config = super(GradientReversal, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\"\"\"         \n",
    "Building guidable model \n",
    "\"\"\"\n",
    "def get_baseline_model(hp_lambda=0., c_list=[]):\n",
    "    base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    layers_list=['conv2d_92', 'conv2d_93', 'conv2d_88', 'conv2d_89', 'conv2d_86']\n",
    "    #layers_list=[]\n",
    "    for i in range(len(base_model.layers[:])):\n",
    "        layer=base_model.layers[i]\n",
    "        if layer.name in layers_list:\n",
    "            print layer.name\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    feature_output=base_model.layers[-1].output\n",
    "    gap_layer_output = keras.layers.GlobalAveragePooling2D()(feature_output)\n",
    "    feature_output = Dense(2048, activation='relu', name='finetuned_features1',kernel_regularizer=keras.regularizers.l2(0.01))(gap_layer_output) \n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(512, activation='relu', name='finetuned_features2',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(256, activation='relu', name='finetuned_features3',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    finetuning = Dense(1,name='predictions')(feature_output)\n",
    "    if 'domain' in CONCEPT:\n",
    "        grl_layer=GradientReversal(hp_lambda=hp_lambda)\n",
    "        feature_output_grl = grl_layer(feature_output)\n",
    "        domain_adversarial = keras.layers.Dense(7, activation = keras.layers.Activation('softmax'), name='domain_adversarial')(feature_output_grl)\n",
    "        output_nodes=[finetuning, domain_adversarial]\n",
    "    else:\n",
    "        output_nodes=[finetuning]\n",
    "    for c in c_list:\n",
    "        if c!='domain':\n",
    "            concept_layer=  keras.layers.Dense(1, activation = keras.layers.Activation('linear'), name='extra_{}'.format(c.strip(' ')))(feature_output)\n",
    "            output_nodes.append(concept_layer)\n",
    "    model = Model(input=base_model.input, output=output_nodes)\n",
    "    if 'domain' in CONCEPT:\n",
    "        model.grl_layer=grl_layer\n",
    "    return model\n",
    "\n",
    "\"\"\" \n",
    "LOSS FUNCTIONS\n",
    "\"\"\"\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def bbce(y_true, y_pred):\n",
    "    # we use zero weights to set the loss to zero for unlabeled data\n",
    "    verbose=0\n",
    "    zero= tf.constant(-1, dtype=tf.float32)\n",
    "    where = tf.not_equal(y_true, zero)\n",
    "    where = tf.reshape(where, [-1])\n",
    "    indices=tf.where(where) #indices where the item of y_true is NOT -1\n",
    "    indices = tf.reshape(indices, [-1])\n",
    "    sliced_y_true = tf.nn.embedding_lookup(y_true, indices)\n",
    "    sliced_y_pred = tf.nn.embedding_lookup(y_pred, indices)\n",
    "    n1 = tf.shape(indices)[0] #number of train images in batch\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    n2 = batch_size - n1 #number of test images in batch\n",
    "    sliced_y_true = tf.reshape(sliced_y_true, [n1, -1])\n",
    "    n1_ = tf.cast(n1, tf.float32)\n",
    "    n2_ = tf.cast(n2, tf.float32)\n",
    "    multiplier = (n1_+ n2_) / n1_\n",
    "    zero_class = tf.constant(0, dtype=tf.float32)\n",
    "    where_class_is_zero=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, zero_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_zero=tf.Print(where_class_is_zero,[where_class_is_zero],'where_class_is_zero: ')\n",
    "    class_weight_zero = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_zero, dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        class_weight_zero=tf.Print(class_weight_zero,[class_weight_zero],'class_weight_zero: ')\n",
    "    one_class = tf.constant(1, dtype=tf.float32)\n",
    "    where_class_is_one=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, one_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_one=tf.Print(where_class_is_one,[where_class_is_one],'where_class_is_one: ')\n",
    "        n1_=tf.Print(n1_,[n1_],'n1_: ')\n",
    "    class_weight_one = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_one,dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    class_weight_zero =  tf.constant(23477.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    class_weight_one =  tf.constant(123820.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    A = tf.ones(tf.shape(sliced_y_true), dtype=tf.float32) - sliced_y_true \n",
    "    A = tf.scalar_mul(class_weight_zero, A)\n",
    "    B = tf.scalar_mul(class_weight_one, sliced_y_true) \n",
    "    class_weight_vector=A+B\n",
    "    ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=sliced_y_true,logits=sliced_y_pred)\n",
    "    ce = tf.multiply(class_weight_vector,ce)\n",
    "    return tf.reduce_mean(ce)\n",
    "\n",
    "from keras.initializers import Constant\n",
    "global domain_weight\n",
    "global main_task_weight\n",
    "\n",
    "\"\"\"\n",
    "EVALUATION FUNCTIONs\n",
    "\"\"\"\n",
    "def accuracy_domain(y_true,y_pred):\n",
    "    #y_p_r=\n",
    "    y_p_r = np.asarray([np.argmax(y_pred[i,:]) for i in range(len(y_pred[:,0]))])\n",
    "    #y_p_r=np.round(y_pred)\n",
    "    y_true = np.asarray([np.argmax(y_true[i,:]) for i in range(len(y_true[:,0]))])\n",
    "    acc = np.equal(y_p_r, y_true)**1.\n",
    "    acc = np.mean(np.float32(acc))\n",
    "    return acc\n",
    "def my_sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def my_accuracy_np(y_true, y_pred):\n",
    "    sliced_y_pred = my_sigmoid(y_pred)\n",
    "    y_pred_rounded = np.round(sliced_y_pred)\n",
    "    acc = np.equal(y_pred_rounded, y_true)**1.\n",
    "    acc = np.mean(np.float32(acc))\n",
    "    return acc\n",
    "def r_square_np(y_true, y_pred):\n",
    "    SS_res =  np.sum(np.square(y_true - y_pred))\n",
    "    SS_tot = np.sum(np.square(y_true - np.mean(y_true)))\n",
    "    r2_mine=( 1 - SS_res/(SS_tot + keras.backend.epsilon()) )\n",
    "    return ( 1 - SS_res/(SS_tot + keras.backend.epsilon()) )\n",
    "\n",
    "global report_val_acc \n",
    "global report_val_r2\n",
    "global report_val_mse\n",
    "report_val_acc=[]\n",
    "report_val_r2=[]\n",
    "report_val_mse=[]\n",
    "# LOG FILE\n",
    "global log_file\n",
    "\n",
    "\"\"\"\n",
    "DATA GENERATORS CREATION\n",
    "\"\"\"\n",
    "train_generator=DataGenerator(data_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=0)\n",
    "train_generator2=DataGenerator(data_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1)#get_batch_data(data_list, batch_size=BATCH_SIZE)\n",
    "val_generator=DataGenerator(val_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(val_list, batch_size=BATCH_SIZE)\n",
    "val_generator2= DataGenerator(val_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(val_list, batch_size=BATCH_SIZE)\n",
    "test_generator= DataGenerator(test_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(test_list, batch_size=BATCH_SIZE)\n",
    "print('data generators created')\n",
    "\"\"\" \n",
    "Get trainable model with Baseline Loss weighting\n",
    "\"\"\"\n",
    "def compile_base_model(baseline_model, opt, concept_list=CONCEPT, loss=None, metrics=None):\n",
    "    losses = [bbce, 'categorical_crossentropy']\n",
    "    loss_weights=[1.,1.]\n",
    "    for i in range(1,len(concept_list)):\n",
    "        losses.append('mean_squared_error')\n",
    "        loss_weights.append(1.)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "             loss=losses,\n",
    "              loss_weights=loss_weights, \n",
    "               metrics=[my_acc_f, r_square])\n",
    "    return \n",
    "verbose=True\n",
    "def custom_train_model(baseline_model,\n",
    "                       epochs= 1, \n",
    "                       lr=1e-4, verbose=True,\n",
    "                       train_generator=train_generator,\n",
    "                       val_generator=val_generator,\n",
    "                       grl_layer=None,\n",
    "                      ):\n",
    "\n",
    "    opt = keras.optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    compile_base_model(baseline_model,opt,loss=None,metrics=None)\n",
    "    history = baseline_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch= len(data_list) // (BATCH_SIZE ),\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    verbose=verbose,\n",
    "                    workers=4,\n",
    "                    use_multiprocessing=False,\n",
    "                    validation_data= val_generator,\n",
    "                    validation_steps= len(val_list)//BATCH_SIZE) \n",
    "    return baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_sample(data, n_samples=2):\n",
    "    sample_=[data[i] for i in np.random.choice(len(data),n_samples)]\n",
    "    #sample_=[data[i] for i in range(len(data))]\n",
    "    return sample_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END Callbacks\n",
    "#\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
    "    #return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def bbce(y_true, y_pred):\n",
    "    # we use zero weights to set the loss to zero for unlabeled data\n",
    "    verbose=0\n",
    "    zero= tf.constant(-1, dtype=tf.float32)\n",
    "    where = tf.not_equal(y_true, zero)\n",
    "    where = tf.reshape(where, [-1])\n",
    "    indices=tf.where(where) #indices where the item of y_true is NOT -1\n",
    "    indices = tf.reshape(indices, [-1])\n",
    "    sliced_y_true = tf.nn.embedding_lookup(y_true, indices)\n",
    "    sliced_y_pred = tf.nn.embedding_lookup(y_pred, indices)\n",
    "    n1 = tf.shape(indices)[0] #number of train images in batch\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    n2 = batch_size - n1 #number of test images in batch\n",
    "    sliced_y_true = tf.reshape(sliced_y_true, [n1, -1])\n",
    "    n1_ = tf.cast(n1, tf.float32)\n",
    "    n2_ = tf.cast(n2, tf.float32)\n",
    "    multiplier = (n1_+ n2_) / n1_\n",
    "    zero_class = tf.constant(0, dtype=tf.float32)\n",
    "    where_class_is_zero=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, zero_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_zero=tf.Print(where_class_is_zero,[where_class_is_zero],'where_class_is_zero: ')\n",
    "    class_weight_zero = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_zero, dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        class_weight_zero=tf.Print(class_weight_zero,[class_weight_zero],'class_weight_zero: ')\n",
    "    one_class = tf.constant(1, dtype=tf.float32)\n",
    "    where_class_is_one=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, one_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_one=tf.Print(where_class_is_one,[where_class_is_one],'where_class_is_one: ')\n",
    "        n1_=tf.Print(n1_,[n1_],'n1_: ')\n",
    "    class_weight_one = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_one,dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    class_weight_zero =  tf.constant(23477.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    class_weight_one =  tf.constant(123820.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    A = tf.ones(tf.shape(sliced_y_true), dtype=tf.float32) - sliced_y_true \n",
    "    A = tf.scalar_mul(class_weight_zero, A)\n",
    "    B = tf.scalar_mul(class_weight_one, sliced_y_true) \n",
    "    class_weight_vector=A+B\n",
    "    ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=sliced_y_true,logits=sliced_y_pred)\n",
    "    ce = tf.multiply(class_weight_vector,ce)\n",
    "    return tf.reduce_mean(ce)\n",
    "\n",
    "# Custom loss layer\n",
    "from keras.initializers import Constant\n",
    "class CustomMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, **kwargs):\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,), initializer=Constant(0.), trainable=True)]\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "    \n",
    "    def multi_loss(self,  ys_true, ys_pred):\n",
    "        #print len(ys_true)\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        i=0\n",
    "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\n",
    "            precision =K.exp(-log_var[0]) ###MODIFICATION HERE\n",
    "            if i==0:\n",
    "                pred_loss = bbce(y_true, y_pred)\n",
    "                term = precision*pred_loss + 0.5 * log_var[0]  \n",
    "                #term=tf.Print(term, [term], 'bbce: ')\n",
    "            else:\n",
    "                pred_loss = keras_mse(y_true, y_pred)\n",
    "                #pred_loss=tf.Print(pred_loss, [pred_loss], 'MSE: ')\n",
    "                term = 0.5 * precision * pred_loss + 0.5 * log_var[0]\n",
    "                #term=tf.Print(term, [term], 'MSE: ')\n",
    "            loss+=term\n",
    "            term = 0.\n",
    "            i+=1\n",
    "        return K.mean(loss)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return K.concatenate(inputs, -1)\n",
    "def get_trainable_model(baseline_model):\n",
    "    inp = keras.layers.Input(shape=(224,224,3,), name='inp')\n",
    "    y1_pred, y2_pred = baseline_model(inp)\n",
    "    y1_true=keras.layers.Input(shape=(1,),name='y1_true')\n",
    "    y2_true=keras.layers.Input(shape=(1,),name='y2_true')\n",
    "    out = CustomMultiLossLayer(nb_outputs=2)([y1_true, y2_true, y1_pred, y2_pred])\n",
    "    return Model(input=[inp, y1_true, y2_true], output=out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_88\n",
      "conv2d_89\n",
      "conv2d_92\n",
      "conv2d_93\n",
      "conv2d_86\n"
     ]
    }
   ],
   "source": [
    "model=get_baseline_model(hp_lambda=1., c_list=CONCEPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features1 (Dense)     (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           finetuned_features1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features2 (Dense)     (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           finetuned_features2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features3 (Dense)     (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           finetuned_features3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "extra_full_contrast (Dense)     (None, 1)            257         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,180,066\n",
      "Trainable params: 7,802,114\n",
      "Non-trainable params: 19,377,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_folder+'/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features1 (Dense)     (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           finetuned_features1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features2 (Dense)     (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           finetuned_features2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features3 (Dense)     (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           finetuned_features3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "extra_full_contrast (Dense)     (None, 1)            257         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,180,066\n",
      "Trainable params: 7,802,114\n",
      "Non-trainable params: 19,377,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def standard_evaluate(input_,pred_, save_file=None, c_list=CONCEPT):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    y_true = input_[0]\n",
    "    min_idx=0\n",
    "    if 'domain' in c_list:\n",
    "        domain_true = input_[1]\n",
    "        min_idx=1\n",
    "    \n",
    "    true_extra_concepts={}\n",
    "    if len(c_list)>min_idx:\n",
    "        for i in range(min_idx, len(c_list)):\n",
    "            true_extra_concepts[i]=input_[min_idx+i]\n",
    "    \n",
    "    y_pred = pred_[0]\n",
    "    if 'domain' in c_list:\n",
    "        domain_pred = pred_[1]\n",
    "        min_idx=1\n",
    "    pred_extra_concepts={}\n",
    "    if len(c_list)>min_idx:\n",
    "        for i in range(min_idx, len(c_list)):\n",
    "            pred_extra_concepts[i]=pred_[min_idx+i]\n",
    "    \n",
    "    val_acc = my_accuracy_np(y_true, y_pred)\n",
    "    if 'domain' in c_list:\n",
    "        val_acc_d = accuracy_domain(domain_true, domain_pred)\n",
    "    val_r2={}\n",
    "    val_mse={}\n",
    "    if len(c_list)>1:\n",
    "        for i in range(1, len(c_list)):\n",
    "            val_r2[i] = r_square_np(true_extra_concepts[i], pred_extra_concepts[i])\n",
    "            val_mse[i] = compute_mse(true_extra_concepts[i], pred_extra_concepts[i])\n",
    "    \n",
    "    extra_string=''\n",
    "    if len(c_list)>1:\n",
    "        for i in range(1, len(c_list)):\n",
    "            extra_string=extra_string+\" {}: r2 {}, mse {}; \".format(i, val_r2[i], val_mse[i])\n",
    "    #print(\"Acc: {}, Acc domain: {}\\n\".format(val_acc, val_acc_d)+extra_string)\n",
    "    save_file=None\n",
    "    if save_file is not None:\n",
    "        if 'domain' in c_list:\n",
    "            save_file.write(\"Val acc: {}, acc_domain: {}\\n\".format(val_acc, val_acc_d)+extra_string)\n",
    "        else:\n",
    "            save_file.write(\"Val acc: {}, \\n\".format(val_acc)+extra_string)\n",
    "    if 'domain' in c_list:\n",
    "        return y_true, domain_true, true_extra_concepts, y_pred, domain_pred, pred_extra_concepts\n",
    "    else:\n",
    "        return y_true, true_extra_concepts, y_pred, pred_extra_concepts\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse\n",
    "def evaluate_model(d_list, model, batch_size=BATCH_SIZE, test_type='', save_file=None):\n",
    "    batch_size=32\n",
    "    t_gen=DataGenerator(d_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=0)\n",
    "    steps=len(d_list)//batch_size\n",
    "    initial_lr = 1e-4\n",
    "    opt = keras.optimizers.SGD(lr=initial_lr, momentum=0.9, nesterov=True)\n",
    "    compile_model(t_m,opt,loss=None,metrics=None)\n",
    "    callbacks = []\n",
    "    y_true=np.zeros(len(d_list))\n",
    "    y_pred=np.zeros((len(d_list),1))\n",
    "    N=0\n",
    "    all_true_domain=[]\n",
    "    all_pred_domain=[]\n",
    "    all_true_extra_cm={}#[]#np.zeros(len(d_list))\n",
    "    all_pred_extra_cm={}#[]#np.zeros(len(d_list))\n",
    "    batch_counter=0\n",
    "    while N<len(d_list):\n",
    "        #print N\n",
    "        input_,labels = t_gen.__getitem__(batch_counter)\n",
    "        pred_ = t_m.predict(input_)\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        if 'domain' in CONCEPT:\n",
    "            y_true_batch, d_true, true_ec, y_pred_batch, d_pred, pred_ec = standard_evaluate(labels,pred_)\n",
    "        else: \n",
    "            y_true_batch, true_ec, y_pred_batch, pred_ec = standard_evaluate(labels,pred_)\n",
    "        #maybe some import pdb here\n",
    "        y_true[N:N+len(y_true_batch)]=y_true_batch.reshape(len(y_true_batch))\n",
    "        y_pred[N:N+len(y_pred_batch)]=y_pred_batch.reshape(len(y_pred_batch),1)\n",
    "        if 'domain' in CONCEPT:\n",
    "            all_true_domain.append(d_true)\n",
    "            all_pred_domain.append(d_pred)\n",
    "        for extra_concept in true_ec.keys():\n",
    "            try:\n",
    "                all_true_extra_cm[extra_concept].append(true_ec[extra_concept])\n",
    "            except:\n",
    "                all_true_extra_cm[extra_concept]=[]\n",
    "                all_true_extra_cm[extra_concept].append(true_ec[extra_concept])\n",
    "        for extra_concept in pred_ec.keys():\n",
    "            try:\n",
    "                all_pred_extra_cm[extra_concept].append(pred_ec[extra_concept])\n",
    "            except:\n",
    "                all_pred_extra_cm[extra_concept]=[]\n",
    "                all_pred_extra_cm[extra_concept].append(pred_ec[extra_concept])\n",
    "        N+=len(y_pred_batch)\n",
    "        batch_counter+=1\n",
    "    #import pdb; pdb.set_trace()\n",
    "    y_true=y_true.reshape((len(d_list),1))\n",
    "    #y_pred=y_pred.reshape((len(d_list),1))\n",
    "    acc = my_accuracy(y_true, y_pred).eval(session=tf.Session())\n",
    "    sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    y_pred_rounded = K.round(sliced_y_pred)\n",
    "    acc_sc = accuracy_score(y_pred_rounded.eval(session=tf.Session()), y_true)\n",
    "    print('accuracy: ', acc_sc)\n",
    "    \n",
    "    y_pred = sliced_y_pred.eval(session=tf.Session())\n",
    "    #sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    #y_pred_rounded = K.round(sliced_y_pred)\n",
    "    auc_score=sklearn.metrics.roc_auc_score(y_true,sliced_y_pred.eval(session=tf.Session()))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(1):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example: {}'.format(roc_auc[0]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    if test_type is not None:\n",
    "        auc_record = open('{}/auc_{}.txt'.format(model_folder,test_type), 'w')\n",
    "        auc_record.write('{}'.format(roc_auc[0]))\n",
    "        print('saved in {}/auc_{}.txt'.format(model_folder,test_type))\n",
    "        auc_record.close()\n",
    "    return all_true_domain, all_true_extra_cm, all_pred_domain, all_pred_extra_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Main Task\n",
    "##### How do we do on the patch classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "model.load_weights(model_folder+'/best_model.h5')\n",
    "t_m = model\n",
    "#all_true_domain, all_true_extra_cm, all_pred_domain, all_pred_extra_cm=evaluate_model(train_list[:1000],t_m, test_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR]: tumor_extra17, tumor/level7/centre1/patient034/node3/patches, 483, full_contrast with path tumor_extra17/tumor/level7/centre1/patient034/node3/patches/483/full_contrast\n",
      "('accuracy: ', 0.8002947678703022)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved in /home/mara/multitask_adversarial/results/STANDARD_FCONTRAST_2409//auc_internal.txt\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "#t_m.load_weights(model_folder+'/best_model.h5')\n",
    "t_m=model\n",
    "all_true_domain_i, all_true_extra_cm_i, all_pred_domain_i, all_pred_extra_cm_i=evaluate_model(test_list,t_m, test_type='internal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy: ', 0.578)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved in /home/mara/multitask_adversarial/results/STANDARD_FCONTRAST_2409//auc_external.txt\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "#t_m.load_weights(model_folder+'/best_model.h5')\n",
    "all_true_domain_e, all_true_extra_cm_e, all_pred_domain_e, all_pred_extra_cm_e=evaluate_model(test2_list,t_m, test_type='external')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pbd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bca44f4c768e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpbd\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named pbd"
     ]
    }
   ],
   "source": [
    "import pbd; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_i=[]\n",
    "for i in range(100):\n",
    "    test_list_b=get_bootstrap_sample(test_list, n_samples=len(test_list))\n",
    "    all_cm_i, all_p_cm_i, roc_auc=evaluate_model(test_list_b,t_m, test_type='internal',save_file=None)\n",
    "    aucs_i.append(roc_auc)\n",
    "print \"AUC avg (std): {} ({})\".format(np.mean(aucs_i), np.std(aucs_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_e=[]\n",
    "for i in range(100):\n",
    "    test2_list_b=get_bootstrap_sample(test2_list, n_samples=len(test2_list))\n",
    "    all_cm_e, all_p_cm_e, roc_auc=evaluate_model(test2_list_b,t_m, test_type='external')\n",
    "    aucs_e.append(roc_auc)\n",
    "print \"AUC avg (std): {} ({})\".format(np.mean(aucs_e), np.std(aucs_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Auxiliary tasks\n",
    "## Are we learning the concepts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsquared(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    # total sum of squares, TTS\n",
    "    average_y = np.mean(labels)\n",
    "    total_errors = labels - average_y\n",
    "    total_sum_squares = np.sum(np.asarray([pow(total_errors[i],2) for i in range(len(total_errors))]))\n",
    "    #rsquared is 1-RSS/TTS\n",
    "    rss_over_tts =   sum_squared_errors/total_sum_squares\n",
    "    rsquared = 1-rss_over_tts\n",
    "    return rsquared\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_i = compute_rsquared(all_cm_i, all_p_cm_i)\n",
    "mse_i = compute_mse(all_cm_i, all_p_cm_i)\n",
    "print 'Internal: ', r2_i, mse_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_e = compute_rsquared(all_cm_e, all_p_cm_e)\n",
    "mse_e = compute_mse(all_cm_e, all_p_cm_e)\n",
    "print 'External: ', r2_e, mse_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type='internal'\n",
    "auc_record = open('{}/concept_metrics_{}.txt'.format(model_folder,test_type), 'w')\n",
    "auc_record.write('{}, {}'.format(r2_i, mse_i))\n",
    "auc_record.close()\n",
    "test_type='external'\n",
    "auc_record = open('{}/concept_metrics_{}.txt'.format(model_folder,test_type), 'w')\n",
    "auc_record.write('{}, {}'.format(r2_e, mse_e))\n",
    "auc_record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_t = compute_rsquared(all_cm_t, all_p_cm_t)\n",
    "mse_t = compute_mse(all_cm_t, all_p_cm_t)\n",
    "print 'Train: ', r2_t, mse_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_r2=np.load('{}/val_r2_log.npy'.format(model_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.load('{}/training_log.npy'.format(model_folder), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('{}/val_by_epoch.txt'.format(model_folder), 'r')\n",
    "f_l=f.readlines()\n",
    "val_acc=[]\n",
    "val_r2=[]\n",
    "val_mse=[]\n",
    "for line in f_l:\n",
    "    acc=line.split('Val acc: ')[1].split(', r2')[0]\n",
    "    val_acc.append(acc)\n",
    "    r2=line.split(', r2:')[1].split(', mse:')[0]\n",
    "    mse=line.split(', mse:')[1].split('\\n')[0]\n",
    "    val_r2.append(r2)\n",
    "    val_mse.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_acc, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_r2, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_mse, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
