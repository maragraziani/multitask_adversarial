{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "res_folders=os.listdir('../../results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(0)# str(hvd.local_rank())\n",
    "keras.backend.set_session(tf.Session(config=config))\n",
    "verbose=1 \n",
    "init=tf.global_variables_initializer() #initialize_all_variables()\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder='/home/mara/multitask_adversarial/results/STANDARD_NAREA/'\n",
    "CONCEPT=['narea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../doc/data_shuffle.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../../doc/data_shuffle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder=model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using brightness standardization\n",
      "data generators created\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RUN SEQUENTIAL\n",
    "python hvd_train_unc.py SEED EXPERIMENT_TYPE \n",
    "\"\"\"\n",
    "BATCH_SIZE=32\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "from keras import *\n",
    "import setproctitle\n",
    "SERVER_NAME = 'ultrafast'\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "sys.path.append('../../lib/TASK_2_UC1/')\n",
    "from models import *\n",
    "from util import otsu_thresholding\n",
    "from extract_xml import *\n",
    "from functions import *                   \n",
    "sys.path.append('../../lib/')\n",
    "from mlta import *\n",
    "import math\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "cam16 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/cam16_500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "all500 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/all500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "extra17 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/extra17/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "tumor_extra17=hd.File('/home/mara/adversarialMICCAI/data/ultrafast/1129-1155/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "test2 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/test_data2/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "pannuke= hd.File('/home/mara/adversarialMICCAI/data/ultrafast/pannuke/patches_fix.h5py', 'r', libver='latest', swmr=True)\n",
    "global data\n",
    "data={'cam16':cam16,'all500':all500,'extra17':extra17, 'tumor_extra17':tumor_extra17, 'test_data2': test2, 'pannuke':pannuke}\n",
    "global concept_db\n",
    "concept_db = hd.File('../../data/normalized_cmeasures/concept_values_def.h5py','r', libver='latest', swmr=True)\n",
    "\n",
    "\n",
    "# DATA SPLIT CSVs \n",
    "train_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/train_shuffle.csv', 'r') # How is the encoding of .csv files ?\n",
    "val_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/val_shuffle.csv', 'r')\n",
    "test_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/test_shuffle.csv', 'r')\n",
    "train_list=train_csv.readlines()\n",
    "val_list=val_csv.readlines()\n",
    "test_list=test_csv.readlines()\n",
    "test2_csv = open('/mnt/nas2/results/IntermediateResults/Camelyon/test2_shuffle.csv', 'r')\n",
    "test2_list=test2_csv.readlines()\n",
    "test2_csv.close()\n",
    "train_csv.close()\n",
    "val_csv.close()\n",
    "test_csv.close()\n",
    "data_csv=open('../../doc/data_shuffle.csv', 'r')\n",
    "data_list=data_csv.readlines()\n",
    "data_csv.close()\n",
    "\n",
    "\n",
    "# STAIN NORMALIZATION\n",
    "def get_normalizer(patch, save_folder=''):\n",
    "    normalizer = ReinhardNormalizer()\n",
    "    normalizer.fit(patch)\n",
    "    np.save('{}/normalizer'.format(save_folder),normalizer)\n",
    "    np.save('{}/normalizing_patch'.format(save_folder), patch)\n",
    "    #print('Normalisers saved to disk.')\n",
    "    return normalizer\n",
    "def normalize_patch(patch, normalizer):\n",
    "    return np.float64(normalizer.transform(np.uint8(patch)))\n",
    "\n",
    "# LOAD DATA NORMALIZER\n",
    "global normalizer\n",
    "db_name, entry_path, patch_no = get_keys(data_list[0])\n",
    "normalization_reference_patch = data[db_name][entry_path][patch_no]\n",
    "normalizer = get_normalizer(normalization_reference_patch, save_folder=new_folder)\n",
    "\n",
    "\"\"\"\n",
    "Batch generators: \n",
    "They load a patch list: a list of file names and paths. \n",
    "They use the list to create a batch of 32 samples. \n",
    "\"\"\"\n",
    "\n",
    "# Retrieve Concept Measures\n",
    "def get_concept_measure(db_name, entry_path, patch_no, measure_type=''):\n",
    "    if measure_type=='domain':\n",
    "        return get_domain(db_name, entry_path)\n",
    "    path=db_name+'/'+entry_path+'/'+str(patch_no)+'/'+measure_type.strip(' ')\n",
    "    try:\n",
    "        cm=concept_db[path][0]\n",
    "        return cm\n",
    "    except:\n",
    "        print(\"[ERR]: {}, {}, {}, {} with path {}\".format(db_name, entry_path, patch_no, measure_type, path))\n",
    "        return 1.\n",
    "    \n",
    "\n",
    "# BATCH GENERATORS\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, patch_list, concept=CONCEPT, batch_size=32, shuffle=True, data_type=0):\n",
    "        self.batch_size=batch_size\n",
    "        self.patch_list=patch_list\n",
    "        self.shuffle=shuffle\n",
    "        self.concept = concept\n",
    "        self.data_type=data_type\n",
    "        #print 'data type:', data_type\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.patch_list)/self.batch_size))\n",
    "    def __getitem__(self, index):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        indexes=self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        patch_list_temp=[self.patch_list[k] for k in indexes]\n",
    "        self.patch_list_temp=patch_list_temp\n",
    "        return self.__data_generation(self)\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.patch_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def __data_generation(self, patch_list_temp):\n",
    "        patch_list_temp=self.patch_list_temp\n",
    "        batch_x=np.zeros((len(patch_list_temp), 224,224,3))\n",
    "        batch_y=np.zeros(len(patch_list_temp))\n",
    "        i=0\n",
    "        for line in patch_list_temp:\n",
    "            db_name, entry_path, patch_no = get_keys(line)\n",
    "            patch=data[db_name][entry_path][patch_no]\n",
    "            patch=normalize_patch(patch, normalizer)\n",
    "            patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "            label = get_class(line, entry_path) \n",
    "            if self.data_type!=0:\n",
    "                label=get_test_label(entry_path)\n",
    "            batch_x[i]=patch\n",
    "            batch_y[i]=label\n",
    "            i+=1\n",
    "        generator_output=[batch_y]\n",
    "        for c in self.concept:\n",
    "            batch_concept_values=np.zeros(len(patch_list_temp))\n",
    "            i=0\n",
    "            for line in patch_list_temp:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                batch_concept_values[i]=get_concept_measure(db_name, entry_path, patch_no, measure_type=c)\n",
    "                i+=1\n",
    "            if c=='domain':\n",
    "                    batch_concept_values=keras.utils.to_categorical(batch_concept_values, num_classes=7)\n",
    "            generator_output.append(batch_concept_values)\n",
    "        return batch_x, generator_output # batch_x, np.asarray(batch_y), generator_output[1], generator_output[2]\n",
    "\n",
    "\"\"\"\n",
    "Credits for the Gradient Reversal Layer\n",
    "https://github.com/michetonu/gradient_reversal_keras_tf/blob/master/flipGradientTF.py\n",
    "\"\"\"\n",
    "def reverse_gradient(X, hp_lambda):\n",
    "    '''Flips the sign of the incoming gradient during training.'''\n",
    "    hp_lambda = hp_lambda\n",
    "    try:\n",
    "        reverse_gradient.num_calls += 1\n",
    "    except AttributeError:\n",
    "        reverse_gradient.num_calls = 1\n",
    "    grad_name = \"GradientReversal%d\" % reverse_gradient.num_calls\n",
    "    @tf.RegisterGradient(grad_name)\n",
    "    def _flip_gradients(op, grad):\n",
    "        grad = tf.negative(grad)\n",
    "        #grad = tf.Print(grad, [grad], 'grad')\n",
    "        final_val = grad * hp_lambda \n",
    "        #final_val =tf.Print(final_val, [final_val], 'final_val')\n",
    "        return [final_val]\n",
    "    g = keras.backend.get_session().graph\n",
    "    with g.gradient_override_map({'Identity': grad_name}):\n",
    "        y = tf.identity(X)\n",
    "    return y\n",
    "\n",
    "class Hp_lambda():\n",
    "    def __init__(self,in_val):\n",
    "        self.value=in_val\n",
    "    def update(self,new_val):\n",
    "        self.value=new_val\n",
    "    def get_hyperparameter_lambda(self):\n",
    "        #val = tf.Print(self.value,[self.value],'hplambda: ')\n",
    "        return tf.Variable(self.value, name='hp_lambda')\n",
    "    #return lmb\n",
    "class GradientReversal(Layer):\n",
    "    '''Flip the sign of gradient during training.'''\n",
    "    def __init__(self, hp_lambda, **kwargs):\n",
    "        super(GradientReversal, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "        self.hp_lambda = Hp_lambda(hp_lambda)\n",
    "        #self.hp_lambda = tf.Variable(hp_lambda, name='hp_lambda')\n",
    "        #self.hp_lambda = tf.Variable(hp_lambda, name='hp_lambda')\n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "        return\n",
    "    def call(self, x, mask=None):\n",
    "        #tf.Print(self.hp_lambda, [self.hp_lambda],'self.hp_lambda: ')\n",
    "        #with tf.Session() as sess:  print(self.hp_lambda.eval()) \n",
    "        lmb=self.hp_lambda.get_hyperparameter_lambda()\n",
    "        return reverse_gradient(x, lmb)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__,\n",
    "                  'hp_lambda': keras.backend.get_value(self.hp_lambda)}\n",
    "        base_config = super(GradientReversal, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\"\"\"         \n",
    "Building guidable model \n",
    "\"\"\"\n",
    "def get_baseline_model(hp_lambda=0., c_list=[]):\n",
    "    base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    layers_list=['conv2d_92', 'conv2d_93', 'conv2d_88', 'conv2d_89', 'conv2d_86']\n",
    "    #layers_list=[]\n",
    "    for i in range(len(base_model.layers[:])):\n",
    "        layer=base_model.layers[i]\n",
    "        if layer.name in layers_list:\n",
    "            print layer.name\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    feature_output=base_model.layers[-1].output\n",
    "    gap_layer_output = keras.layers.GlobalAveragePooling2D()(feature_output)\n",
    "    feature_output = Dense(2048, activation='relu', name='finetuned_features1',kernel_regularizer=keras.regularizers.l2(0.01))(gap_layer_output) \n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(512, activation='relu', name='finetuned_features2',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(256, activation='relu', name='finetuned_features3',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    finetuning = Dense(1,name='predictions')(feature_output)\n",
    "    if 'domain' in CONCEPT:\n",
    "        grl_layer=GradientReversal(hp_lambda=hp_lambda)\n",
    "        feature_output_grl = grl_layer(feature_output)\n",
    "        domain_adversarial = keras.layers.Dense(7, activation = keras.layers.Activation('softmax'), name='domain_adversarial')(feature_output_grl)\n",
    "        output_nodes=[finetuning, domain_adversarial]\n",
    "    else:\n",
    "        output_nodes=[finetuning]\n",
    "    for c in c_list:\n",
    "        if c!='domain':\n",
    "            concept_layer=  keras.layers.Dense(1, activation = keras.layers.Activation('linear'), name='extra_{}'.format(c.strip(' ')))(feature_output)\n",
    "            output_nodes.append(concept_layer)\n",
    "    model = Model(input=base_model.input, output=output_nodes)\n",
    "    if 'domain' in CONCEPT:\n",
    "        model.grl_layer=grl_layer\n",
    "    return model\n",
    "\n",
    "\"\"\" \n",
    "LOSS FUNCTIONS\n",
    "\"\"\"\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def bbce(y_true, y_pred):\n",
    "    # we use zero weights to set the loss to zero for unlabeled data\n",
    "    verbose=0\n",
    "    zero= tf.constant(-1, dtype=tf.float32)\n",
    "    where = tf.not_equal(y_true, zero)\n",
    "    where = tf.reshape(where, [-1])\n",
    "    indices=tf.where(where) #indices where the item of y_true is NOT -1\n",
    "    indices = tf.reshape(indices, [-1])\n",
    "    sliced_y_true = tf.nn.embedding_lookup(y_true, indices)\n",
    "    sliced_y_pred = tf.nn.embedding_lookup(y_pred, indices)\n",
    "    n1 = tf.shape(indices)[0] #number of train images in batch\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    n2 = batch_size - n1 #number of test images in batch\n",
    "    sliced_y_true = tf.reshape(sliced_y_true, [n1, -1])\n",
    "    n1_ = tf.cast(n1, tf.float32)\n",
    "    n2_ = tf.cast(n2, tf.float32)\n",
    "    multiplier = (n1_+ n2_) / n1_\n",
    "    zero_class = tf.constant(0, dtype=tf.float32)\n",
    "    where_class_is_zero=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, zero_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_zero=tf.Print(where_class_is_zero,[where_class_is_zero],'where_class_is_zero: ')\n",
    "    class_weight_zero = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_zero, dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        class_weight_zero=tf.Print(class_weight_zero,[class_weight_zero],'class_weight_zero: ')\n",
    "    one_class = tf.constant(1, dtype=tf.float32)\n",
    "    where_class_is_one=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, one_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_one=tf.Print(where_class_is_one,[where_class_is_one],'where_class_is_one: ')\n",
    "        n1_=tf.Print(n1_,[n1_],'n1_: ')\n",
    "    class_weight_one = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_one,dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    class_weight_zero =  tf.constant(23477.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    class_weight_one =  tf.constant(123820.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    A = tf.ones(tf.shape(sliced_y_true), dtype=tf.float32) - sliced_y_true \n",
    "    A = tf.scalar_mul(class_weight_zero, A)\n",
    "    B = tf.scalar_mul(class_weight_one, sliced_y_true) \n",
    "    class_weight_vector=A+B\n",
    "    ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=sliced_y_true,logits=sliced_y_pred)\n",
    "    ce = tf.multiply(class_weight_vector,ce)\n",
    "    return tf.reduce_mean(ce)\n",
    "\n",
    "from keras.initializers import Constant\n",
    "global domain_weight\n",
    "global main_task_weight\n",
    "\n",
    "\"\"\"\n",
    "EVALUATION FUNCTIONs\n",
    "\"\"\"\n",
    "def accuracy_domain(y_true,y_pred):\n",
    "    #y_p_r=\n",
    "    y_p_r = np.asarray([np.argmax(y_pred[i,:]) for i in range(len(y_pred[:,0]))])\n",
    "    #y_p_r=np.round(y_pred)\n",
    "    y_true = np.asarray([np.argmax(y_true[i,:]) for i in range(len(y_true[:,0]))])\n",
    "    acc = np.equal(y_p_r, y_true)**1.\n",
    "    acc = np.mean(np.float32(acc))\n",
    "    return acc\n",
    "def my_sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def my_accuracy_np(y_true, y_pred):\n",
    "    sliced_y_pred = my_sigmoid(y_pred)\n",
    "    y_pred_rounded = np.round(sliced_y_pred)\n",
    "    acc = np.equal(y_pred_rounded, y_true)**1.\n",
    "    acc = np.mean(np.float32(acc))\n",
    "    return acc\n",
    "def r_square_np(y_true, y_pred):\n",
    "    SS_res =  np.sum(np.square(y_true - y_pred))\n",
    "    SS_tot = np.sum(np.square(y_true - np.mean(y_true)))\n",
    "    r2_mine=( 1 - SS_res/(SS_tot + keras.backend.epsilon()) )\n",
    "    return ( 1 - SS_res/(SS_tot + keras.backend.epsilon()) )\n",
    "\n",
    "global report_val_acc \n",
    "global report_val_r2\n",
    "global report_val_mse\n",
    "report_val_acc=[]\n",
    "report_val_r2=[]\n",
    "report_val_mse=[]\n",
    "# LOG FILE\n",
    "global log_file\n",
    "\n",
    "\"\"\"\n",
    "DATA GENERATORS CREATION\n",
    "\"\"\"\n",
    "train_generator=DataGenerator(data_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=0)\n",
    "train_generator2=DataGenerator(data_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1)#get_batch_data(data_list, batch_size=BATCH_SIZE)\n",
    "val_generator=DataGenerator(val_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(val_list, batch_size=BATCH_SIZE)\n",
    "val_generator2= DataGenerator(val_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(val_list, batch_size=BATCH_SIZE)\n",
    "test_generator= DataGenerator(test_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=1) #get_test_batch(test_list, batch_size=BATCH_SIZE)\n",
    "print('data generators created')\n",
    "\"\"\" \n",
    "Get trainable model with Baseline Loss weighting\n",
    "\"\"\"\n",
    "def compile_base_model(baseline_model, opt, concept_list=CONCEPT, loss=None, metrics=None):\n",
    "    losses = [bbce, 'categorical_crossentropy']\n",
    "    loss_weights=[1.,1.]\n",
    "    for i in range(1,len(concept_list)):\n",
    "        losses.append('mean_squared_error')\n",
    "        loss_weights.append(1.)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "             loss=losses,\n",
    "              loss_weights=loss_weights, \n",
    "               metrics=[my_acc_f, r_square])\n",
    "    return \n",
    "verbose=True\n",
    "def custom_train_model(baseline_model,\n",
    "                       epochs= 1, \n",
    "                       lr=1e-4, verbose=True,\n",
    "                       train_generator=train_generator,\n",
    "                       val_generator=val_generator,\n",
    "                       grl_layer=None,\n",
    "                      ):\n",
    "\n",
    "    opt = keras.optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
    "    compile_base_model(baseline_model,opt,loss=None,metrics=None)\n",
    "    history = baseline_model.fit_generator(train_generator,\n",
    "                    steps_per_epoch= len(data_list) // (BATCH_SIZE ),\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=epochs,\n",
    "                    verbose=verbose,\n",
    "                    workers=4,\n",
    "                    use_multiprocessing=False,\n",
    "                    validation_data= val_generator,\n",
    "                    validation_steps= len(val_list)//BATCH_SIZE) \n",
    "    return baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_sample(data, n_samples=2):\n",
    "    sample_=[data[i] for i in np.random.choice(len(data),n_samples)]\n",
    "    #sample_=[data[i] for i in range(len(data))]\n",
    "    return sample_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END Callbacks\n",
    "#\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
    "    #return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def bbce(y_true, y_pred):\n",
    "    # we use zero weights to set the loss to zero for unlabeled data\n",
    "    verbose=0\n",
    "    zero= tf.constant(-1, dtype=tf.float32)\n",
    "    where = tf.not_equal(y_true, zero)\n",
    "    where = tf.reshape(where, [-1])\n",
    "    indices=tf.where(where) #indices where the item of y_true is NOT -1\n",
    "    indices = tf.reshape(indices, [-1])\n",
    "    sliced_y_true = tf.nn.embedding_lookup(y_true, indices)\n",
    "    sliced_y_pred = tf.nn.embedding_lookup(y_pred, indices)\n",
    "    n1 = tf.shape(indices)[0] #number of train images in batch\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    n2 = batch_size - n1 #number of test images in batch\n",
    "    sliced_y_true = tf.reshape(sliced_y_true, [n1, -1])\n",
    "    n1_ = tf.cast(n1, tf.float32)\n",
    "    n2_ = tf.cast(n2, tf.float32)\n",
    "    multiplier = (n1_+ n2_) / n1_\n",
    "    zero_class = tf.constant(0, dtype=tf.float32)\n",
    "    where_class_is_zero=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, zero_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_zero=tf.Print(where_class_is_zero,[where_class_is_zero],'where_class_is_zero: ')\n",
    "    class_weight_zero = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_zero, dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        class_weight_zero=tf.Print(class_weight_zero,[class_weight_zero],'class_weight_zero: ')\n",
    "    one_class = tf.constant(1, dtype=tf.float32)\n",
    "    where_class_is_one=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, one_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_one=tf.Print(where_class_is_one,[where_class_is_one],'where_class_is_one: ')\n",
    "        n1_=tf.Print(n1_,[n1_],'n1_: ')\n",
    "    class_weight_one = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_one,dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    class_weight_zero =  tf.constant(23477.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    class_weight_one =  tf.constant(123820.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    A = tf.ones(tf.shape(sliced_y_true), dtype=tf.float32) - sliced_y_true \n",
    "    A = tf.scalar_mul(class_weight_zero, A)\n",
    "    B = tf.scalar_mul(class_weight_one, sliced_y_true) \n",
    "    class_weight_vector=A+B\n",
    "    ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=sliced_y_true,logits=sliced_y_pred)\n",
    "    ce = tf.multiply(class_weight_vector,ce)\n",
    "    return tf.reduce_mean(ce)\n",
    "\n",
    "# Custom loss layer\n",
    "from keras.initializers import Constant\n",
    "class CustomMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, **kwargs):\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,), initializer=Constant(0.), trainable=True)]\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "    \n",
    "    def multi_loss(self,  ys_true, ys_pred):\n",
    "        #print len(ys_true)\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        i=0\n",
    "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\n",
    "            precision =K.exp(-log_var[0]) ###MODIFICATION HERE\n",
    "            if i==0:\n",
    "                pred_loss = bbce(y_true, y_pred)\n",
    "                term = precision*pred_loss + 0.5 * log_var[0]  \n",
    "                #term=tf.Print(term, [term], 'bbce: ')\n",
    "            else:\n",
    "                pred_loss = keras_mse(y_true, y_pred)\n",
    "                #pred_loss=tf.Print(pred_loss, [pred_loss], 'MSE: ')\n",
    "                term = 0.5 * precision * pred_loss + 0.5 * log_var[0]\n",
    "                #term=tf.Print(term, [term], 'MSE: ')\n",
    "            loss+=term\n",
    "            term = 0.\n",
    "            i+=1\n",
    "        return K.mean(loss)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return K.concatenate(inputs, -1)\n",
    "def get_trainable_model(baseline_model):\n",
    "    inp = keras.layers.Input(shape=(224,224,3,), name='inp')\n",
    "    y1_pred, y2_pred = baseline_model(inp)\n",
    "    y1_true=keras.layers.Input(shape=(1,),name='y1_true')\n",
    "    y2_true=keras.layers.Input(shape=(1,),name='y2_true')\n",
    "    out = CustomMultiLossLayer(nb_outputs=2)([y1_true, y2_true, y1_pred, y2_pred])\n",
    "    return Model(input=[inp, y1_true, y2_true], output=out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_88\n",
      "conv2d_89\n",
      "conv2d_92\n",
      "conv2d_93\n",
      "conv2d_86\n"
     ]
    }
   ],
   "source": [
    "model=get_baseline_model(hp_lambda=1., c_list=CONCEPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features1 (Dense)     (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           finetuned_features1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features2 (Dense)     (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           finetuned_features2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features3 (Dense)     (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           finetuned_features3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "extra_narea (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,180,066\n",
      "Trainable params: 7,802,114\n",
      "Non-trainable params: 19,377,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_folder+'/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features1 (Dense)     (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           finetuned_features1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features2 (Dense)     (None, 512)          1049088     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           finetuned_features2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features3 (Dense)     (None, 256)          131328      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           finetuned_features3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "extra_narea (Dense)             (None, 1)            257         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,180,066\n",
      "Trainable params: 7,802,114\n",
      "Non-trainable params: 19,377,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def standard_evaluate(input_,pred_, save_file=None, c_list=CONCEPT):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    y_true = input_[0]\n",
    "    min_idx=0\n",
    "    if 'domain' in c_list:\n",
    "        domain_true = input_[1]\n",
    "        min_idx=1\n",
    "    \n",
    "    true_extra_concepts={}\n",
    "    if len(c_list)>min_idx:\n",
    "        for i in range(min_idx, len(c_list)):\n",
    "            true_extra_concepts[i]=input_[min_idx+i]\n",
    "    \n",
    "    y_pred = pred_[0]\n",
    "    if 'domain' in c_list:\n",
    "        domain_pred = pred_[1]\n",
    "        min_idx=1\n",
    "    pred_extra_concepts={}\n",
    "    if len(c_list)>min_idx:\n",
    "        for i in range(min_idx, len(c_list)):\n",
    "            pred_extra_concepts[i]=pred_[min_idx+i]\n",
    "    \n",
    "    val_acc = my_accuracy_np(y_true, y_pred)\n",
    "    if 'domain' in c_list:\n",
    "        val_acc_d = accuracy_domain(domain_true, domain_pred)\n",
    "    val_r2={}\n",
    "    val_mse={}\n",
    "    if len(c_list)>1:\n",
    "        for i in range(1, len(c_list)):\n",
    "            val_r2[i] = r_square_np(true_extra_concepts[i], pred_extra_concepts[i])\n",
    "            val_mse[i] = compute_mse(true_extra_concepts[i], pred_extra_concepts[i])\n",
    "    \n",
    "    extra_string=''\n",
    "    if len(c_list)>1:\n",
    "        for i in range(1, len(c_list)):\n",
    "            extra_string=extra_string+\" {}: r2 {}, mse {}; \".format(i, val_r2[i], val_mse[i])\n",
    "    #print(\"Acc: {}, Acc domain: {}\\n\".format(val_acc, val_acc_d)+extra_string)\n",
    "    save_file=None\n",
    "    if save_file is not None:\n",
    "        if 'domain' in c_list:\n",
    "            save_file.write(\"Val acc: {}, acc_domain: {}\\n\".format(val_acc, val_acc_d)+extra_string)\n",
    "        else:\n",
    "            save_file.write(\"Val acc: {}, \\n\".format(val_acc)+extra_string)\n",
    "    if 'domain' in c_list:\n",
    "        return y_true, domain_true, true_extra_concepts, y_pred, domain_pred, pred_extra_concepts\n",
    "    else:\n",
    "        return y_true, true_extra_concepts, y_pred, pred_extra_concepts\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse\n",
    "def evaluate_model(d_list, model, batch_size=BATCH_SIZE, test_type='', save_file=None):\n",
    "    batch_size=32\n",
    "    t_gen=DataGenerator(d_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=0)\n",
    "    steps=len(d_list)//batch_size\n",
    "    initial_lr = 1e-4\n",
    "    opt = keras.optimizers.SGD(lr=initial_lr, momentum=0.9, nesterov=True)\n",
    "    compile_model(t_m,opt,loss=None,metrics=None)\n",
    "    callbacks = []\n",
    "    y_true=np.zeros(len(d_list))\n",
    "    y_pred=np.zeros((len(d_list),1))\n",
    "    N=0\n",
    "    all_true_domain=[]\n",
    "    all_pred_domain=[]\n",
    "    all_true_extra_cm={}#[]#np.zeros(len(d_list))\n",
    "    all_pred_extra_cm={}#[]#np.zeros(len(d_list))\n",
    "    batch_counter=0\n",
    "    while N<len(d_list):\n",
    "        #print N\n",
    "        input_,labels = t_gen.__getitem__(batch_counter)\n",
    "        pred_ = t_m.predict(input_)\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        if 'domain' in CONCEPT:\n",
    "            y_true_batch, d_true, true_ec, y_pred_batch, d_pred, pred_ec = standard_evaluate(labels,pred_)\n",
    "        else: \n",
    "            y_true_batch, true_ec, y_pred_batch, pred_ec = standard_evaluate(labels,pred_)\n",
    "        #maybe some import pdb here\n",
    "        y_true[N:N+len(y_true_batch)]=y_true_batch.reshape(len(y_true_batch))\n",
    "        y_pred[N:N+len(y_pred_batch)]=y_pred_batch.reshape(len(y_pred_batch),1)\n",
    "        if 'domain' in CONCEPT:\n",
    "            all_true_domain.append(d_true)\n",
    "            all_pred_domain.append(d_pred)\n",
    "        for extra_concept in true_ec.keys():\n",
    "            try:\n",
    "                all_true_extra_cm[extra_concept].append(true_ec[extra_concept])\n",
    "            except:\n",
    "                all_true_extra_cm[extra_concept]=[]\n",
    "                all_true_extra_cm[extra_concept].append(true_ec[extra_concept])\n",
    "        for extra_concept in pred_ec.keys():\n",
    "            try:\n",
    "                all_pred_extra_cm[extra_concept].append(pred_ec[extra_concept])\n",
    "            except:\n",
    "                all_pred_extra_cm[extra_concept]=[]\n",
    "                all_pred_extra_cm[extra_concept].append(pred_ec[extra_concept])\n",
    "        N+=len(y_pred_batch)\n",
    "        batch_counter+=1\n",
    "    #import pdb; pdb.set_trace()\n",
    "    y_true=y_true.reshape((len(d_list),1))\n",
    "    #y_pred=y_pred.reshape((len(d_list),1))\n",
    "    acc = my_accuracy(y_true, y_pred).eval(session=tf.Session())\n",
    "    sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    y_pred_rounded = K.round(sliced_y_pred)\n",
    "    acc_sc = accuracy_score(y_pred_rounded.eval(session=tf.Session()), y_true)\n",
    "    print('accuracy: ', acc_sc)\n",
    "    \n",
    "    y_pred = sliced_y_pred.eval(session=tf.Session())\n",
    "    #sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    #y_pred_rounded = K.round(sliced_y_pred)\n",
    "    auc_score=sklearn.metrics.roc_auc_score(y_true,sliced_y_pred.eval(session=tf.Session()))\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(1):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example: {}'.format(roc_auc[0]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    if test_type is not None:\n",
    "        auc_record = open('{}/auc_{}.txt'.format(model_folder,test_type), 'w')\n",
    "        auc_record.write('{}'.format(roc_auc[0]))\n",
    "        print('saved in {}/auc_{}.txt')\n",
    "        auc_record.close()\n",
    "    return all_true_domain, all_true_extra_cm, all_pred_domain, all_pred_extra_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Main Task\n",
    "##### How do we do on the patch classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-4ae3e83dac24>(8)standard_evaluate()\n",
      "-> y_true = input_[0]\n",
      "(Pdb) n\n",
      "> <ipython-input-17-4ae3e83dac24>(9)standard_evaluate()\n",
      "-> domain_true = input_[1]\n",
      "(Pdb) y_true\n",
      "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "(Pdb) n\n",
      "> <ipython-input-17-4ae3e83dac24>(10)standard_evaluate()\n",
      "-> true_extra_concepts={}\n",
      "(Pdb) domain_trye\n",
      "*** NameError: name 'domain_trye' is not defined\n",
      "(Pdb) domain_true\n",
      "array([ 0.444645  , -0.08386395, -0.13336177, -0.21798707, -0.18605299,\n",
      "       -0.23555081, -0.22916399,  0.24346032,  0.00555146, -0.08067054,\n",
      "       -0.18126288,  0.08698335,  0.45262852,  0.00395476,  0.530867  ,\n",
      "       -0.19563322,  0.60431538, -0.18605299, -0.27067829, -0.0215925 ,\n",
      "        0.24984714, -0.15411892, -0.13336177, -0.24034092, -0.24353433,\n",
      "        0.55002745, -0.4431223 , -0.12697495, -0.4431223 ,  1.39149034,\n",
      "        0.39514718,  0.21950977])\n",
      "(Pdb) n\n",
      "> <ipython-input-17-4ae3e83dac24>(11)standard_evaluate()\n",
      "-> if len(c_list)>1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-13b23a3f7c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#t_m.load_weights(model_folder+'/best_model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_true_domain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_true_extra_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred_domain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred_extra_cm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-4ae3e83dac24>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(d_list, model, batch_size, test_type)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m#import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0my_true_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_ec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;31m#maybe some import pdb here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4ae3e83dac24>\u001b[0m in \u001b[0;36mstandard_evaluate\u001b[0;34m(input_, pred_, save_file, c_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdomain_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrue_extra_concepts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrue_extra_concepts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-4ae3e83dac24>\u001b[0m in \u001b[0;36mstandard_evaluate\u001b[0;34m(input_, pred_, save_file, c_list)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdomain_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrue_extra_concepts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtrue_extra_concepts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/bdb.pyc\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36muser_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_mainpyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbp_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pdb.pyc\u001b[0m in \u001b[0;36minteraction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_stack_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmdloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/cmd.pyc\u001b[0m in \u001b[0;36mcmdloop\u001b[0;34m(self, intro)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rawinput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EOF'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "#t_m.load_weights(model_folder+'/best_model.h5')\n",
    "t_m = model\n",
    "all_true_domain, all_true_extra_cm, all_pred_domain, all_pred_extra_cm=evaluate_model(train_list[:1000],t_m, test_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR]: tumor_extra17, tumor/level7/centre1/patient034/node3/patches, 483, narea with path tumor_extra17/tumor/level7/centre1/patient034/node3/patches/483/narea\n",
      "('accuracy: ', 0.627855563743552)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "global name 'save_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d74dd9c74bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#keras.backend.get_session().run(tf.global_variables_initializer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#t_m.load_weights(model_folder+'/best_model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_true_domain_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_true_extra_cm_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred_domain_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred_extra_cm_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'internal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-98f19c75815d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(d_list, model, batch_size, test_type)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msave_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mauc_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/auc_{}.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mauc_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'save_file' is not defined"
     ]
    }
   ],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "#t_m.load_weights(model_folder+'/best_model.h5')\n",
    "all_true_domain_i, all_true_extra_cm_i, all_pred_domain_i, all_pred_extra_cm_i=evaluate_model(test_list,t_m, test_type='internal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "#t_m.load_weights(model_folder+'/best_model.h5')\n",
    "all_true_domain_e, all_true_extra_cm_e, all_pred_domain_e, all_pred_extra_cm_e=evaluate_model(test2_list,t_m, test_type='external')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_i=[]\n",
    "for i in range(100):\n",
    "    test_list_b=get_bootstrap_sample(test_list, n_samples=len(test_list))\n",
    "    all_cm_i, all_p_cm_i, roc_auc=evaluate_model(test_list_b,t_m, test_type='internal',save_file=None)\n",
    "    aucs_i.append(roc_auc)\n",
    "print \"AUC avg (std): {} ({})\".format(np.mean(aucs_i), np.std(aucs_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_e=[]\n",
    "for i in range(100):\n",
    "    test2_list_b=get_bootstrap_sample(test2_list, n_samples=len(test2_list))\n",
    "    all_cm_e, all_p_cm_e, roc_auc=evaluate_model(test2_list_b,t_m, test_type='external')\n",
    "    aucs_e.append(roc_auc)\n",
    "print \"AUC avg (std): {} ({})\".format(np.mean(aucs_e), np.std(aucs_e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Auxiliary tasks\n",
    "## Are we learning the concepts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsquared(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    # total sum of squares, TTS\n",
    "    average_y = np.mean(labels)\n",
    "    total_errors = labels - average_y\n",
    "    total_sum_squares = np.sum(np.asarray([pow(total_errors[i],2) for i in range(len(total_errors))]))\n",
    "    #rsquared is 1-RSS/TTS\n",
    "    rss_over_tts =   sum_squared_errors/total_sum_squares\n",
    "    rsquared = 1-rss_over_tts\n",
    "    return rsquared\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_i = compute_rsquared(all_cm_i, all_p_cm_i)\n",
    "mse_i = compute_mse(all_cm_i, all_p_cm_i)\n",
    "print 'Internal: ', r2_i, mse_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_e = compute_rsquared(all_cm_e, all_p_cm_e)\n",
    "mse_e = compute_mse(all_cm_e, all_p_cm_e)\n",
    "print 'External: ', r2_e, mse_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type='internal'\n",
    "auc_record = open('{}/concept_metrics_{}.txt'.format(model_folder,test_type), 'w')\n",
    "auc_record.write('{}, {}'.format(r2_i, mse_i))\n",
    "auc_record.close()\n",
    "test_type='external'\n",
    "auc_record = open('{}/concept_metrics_{}.txt'.format(model_folder,test_type), 'w')\n",
    "auc_record.write('{}, {}'.format(r2_e, mse_e))\n",
    "auc_record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_t = compute_rsquared(all_cm_t, all_p_cm_t)\n",
    "mse_t = compute_mse(all_cm_t, all_p_cm_t)\n",
    "print 'Train: ', r2_t, mse_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_r2=np.load('{}/val_r2_log.npy'.format(model_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.load('{}/training_log.npy'.format(model_folder), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('{}/val_by_epoch.txt'.format(model_folder), 'r')\n",
    "f_l=f.readlines()\n",
    "val_acc=[]\n",
    "val_r2=[]\n",
    "val_mse=[]\n",
    "for line in f_l:\n",
    "    acc=line.split('Val acc: ')[1].split(', r2')[0]\n",
    "    val_acc.append(acc)\n",
    "    r2=line.split(', r2:')[1].split(', mse:')[0]\n",
    "    mse=line.split(', mse:')[1].split('\\n')[0]\n",
    "    val_r2.append(r2)\n",
    "    val_mse.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_acc, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_r2, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asarray(val_mse, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
