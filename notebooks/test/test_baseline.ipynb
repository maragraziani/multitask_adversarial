{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder='/home/mara/multitask_adversarial/results/BASEL/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = '0'\n",
    "keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../doc/data_shuffle.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'../../doc/data_shuffle.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Loading OS libraries to configure server preferences\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import setproctitle\n",
    "SERVER_NAME = 'ultrafast'\n",
    "EXPERIMENT_TYPE='test_baseline'\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "## Adding PROCESS_UC1 utilities\n",
    "sys.path.append('../../lib/TASK_2_UC1/')\n",
    "from models import *\n",
    "from util import otsu_thresholding\n",
    "from extract_xml import *\n",
    "from functions import *                   \n",
    "sys.path.append('../../lib/')\n",
    "from mlta import *\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = '0'\n",
    "keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "verbose=1 \n",
    "\n",
    "cam16 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/cam16_500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "all500 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/all500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "extra17 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/extra17/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "tumor_extra17=hd.File('/home/mara/adversarialMICCAI/data/ultrafast/1129-1155/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "test2 = hd.File('/mnt/nas2/results/IntermediateResults/Camelyon/ultrafast/test_data2/patches.hdf5', 'r', libver='latest', swmr=True)\n",
    "pannuke= hd.File('/mnt/nas2/results/IntermediateResults/Camelyon/pannuke/patches_fix.hdf5', 'r', libver='latest', swmr=True)\n",
    "\n",
    "global data\n",
    "data={'cam16':cam16,'all500':all500,'extra17':extra17, 'tumor_extra17':tumor_extra17, 'test_data2': test2, 'pannuke':pannuke}\n",
    "global concept_db\n",
    "concept_db = hd.File('../../data/normalized_cmeasures/concept_values.h5py','r')\n",
    "# Note: nuclei_concepts not supported yet\n",
    "#global nuclei_concepts\n",
    "#nuclei_concepts=hd.File('/mnt/nas2/results/IntermediateResults/Mara/MICCAI2020/normalized.hdf5','r')\n",
    "\n",
    "#SYSTEM CONFIGS \n",
    "CONFIG_FILE = 'doc/config.cfg'\n",
    "COLOR = True\n",
    "global new_folder\n",
    "new_folder=folder_name=model_folder\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "seed=1\n",
    "print seed\n",
    "\n",
    "# SET PROCESS TITLE\n",
    "setproctitle.setproctitle('UC1_{}'.format(EXPERIMENT_TYPE))\n",
    "\n",
    "# SET SEED\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# DATA SPLIT CSVs \n",
    "train_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/train_shuffle.csv', 'r') # How is the encoding of .csv files ?\n",
    "val_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/val_shuffle.csv', 'r')\n",
    "test_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/test_shuffle.csv', 'r')\n",
    "train_list=train_csv.readlines()\n",
    "val_list=val_csv.readlines()\n",
    "test_list=test_csv.readlines()\n",
    "test2_csv = open('/mnt/nas2/results/IntermediateResults/Camelyon/test2_shuffle.csv', 'r')\n",
    "test2_list=test2_csv.readlines()\n",
    "test2_csv.close()\n",
    "train_csv.close()\n",
    "val_csv.close()\n",
    "test_csv.close()\n",
    "#data_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/data_shuffle.csv', 'r')\n",
    "#data_csv=open('./data/train.csv', 'r')\n",
    "data_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/pannuke/pannuke_train_shuffled.csv', 'r')\n",
    "data_list=data_csv.readlines()\n",
    "data_csv.close()\n",
    "\n",
    "# STAIN NORMALIZATION\n",
    "def get_normalizer(patch, save_folder=''):\n",
    "    normalizer = ReinhardNormalizer()\n",
    "    normalizer.fit(patch)\n",
    "    np.save('{}/normalizer'.format(save_folder),normalizer)\n",
    "    np.save('{}/normalizing_patch'.format(save_folder), patch)\n",
    "    print('Normalisers saved to disk.')\n",
    "    return normalizer\n",
    "\n",
    "def normalize_patch(patch, normalizer):\n",
    "    return np.float64(normalizer.transform(np.uint8(patch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using brightness standardization\n",
      "Normalisers saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA NORMALIZER\n",
    "global normalizer\n",
    "db_name, entry_path, patch_no = get_keys(data_list[0])\n",
    "normalization_reference_patch = data[db_name][entry_path][patch_no]\n",
    "normalizer = get_normalizer(normalization_reference_patch, save_folder=new_folder)\n",
    "\n",
    "\"\"\"\n",
    "Building baseline model \n",
    "\"\"\"\n",
    "#\n",
    "# MODEL: BASELINE\n",
    "base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "#base_model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "#base_model = pretrained(ResNet50)((224,224,3),1000)\n",
    "#base_model = wide_resnet(50, 2048)((224,224,3), (1))\n",
    "feature_output=base_model.layers[-1].output\n",
    "feature_output = keras.layers.GlobalAveragePooling2D()(feature_output)\n",
    "feature_output = Dense(2048, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01), name='finetuned_features1')(feature_output)\n",
    "feature_output = Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01), name='finetuned_features2')(feature_output)\n",
    "feature_output = Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01), name='finetuned_features3')(feature_output)\n",
    "finetuning = Dense(1,name='predictions')(feature_output)\n",
    "#regression_output = keras.layers.Dense(1, activation = keras.layers.Activation('linear'), name='concept_regressor')(feature_output)\n",
    "model = Model(input=base_model.input, output=[finetuning])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Batch generators: \n",
    "They load a patch list: a list of file names and paths. \n",
    "They use the list to create a batch of 32 samples. \n",
    "\"\"\"\n",
    "class Generator(Sequence):\n",
    "    # Class is a dataset wrapper for better training performance\n",
    "    def __init__(self, patch_list, batch_size=32):\n",
    "        #self.x, self.y = x_set, y_set\n",
    "        self.patch_list=patch_list\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples=len(patch_list)\n",
    "    def __len__(self):\n",
    "        return self.num_samples/self.batch_size\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            offset = 0\n",
    "            batch_size=self.batch_size\n",
    "            for offset in range(0,self.num_samples, self.batch_size):\n",
    "                batch_x = []\n",
    "                batch_y = []\n",
    "                #batch_ones=[]\n",
    "                #batch_noise=[]\n",
    "                batch_contrast = []\n",
    "                #batch_domain = []\n",
    "                #batch_n_area = [] # nuclei average area\n",
    "                #batch_n_count = []\n",
    "                batch_samples=self.patch_list[offset:offset+batch_size]\n",
    "                for line in batch_samples:\n",
    "                    db_name, entry_path, patch_no = get_keys(line)\n",
    "                    patch=data[db_name][entry_path][patch_no]\n",
    "                    patch=normalize_patch(patch, normalizer)\n",
    "                    patch=keras.applications.inception_v3.preprocess_input(patch) #removed bc of BNorm\n",
    "                    #patch=keras.applications.resnet50.preprocess_input(patch) \n",
    "                    label = get_class(line, entry_path) # is there a problem with get_class ?\n",
    "                    batch_x.append(patch)\n",
    "                    batch_y.append(label)\n",
    "                batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "                batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "                batch_cm=np.ones(len(batch_y), dtype=np.float32)\n",
    "            inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_x = [batch_x, batch_y, batch_cm]\n",
    "            batch_y = batch_y\n",
    "            return batch_x, batch_y\n",
    "#def on_epoch_end(self):\n",
    "    #    np.random.shuffle(self.indices)\n",
    "def get_concept_measure(db_name, entry_path, patch_no, measure_type=''):\n",
    "    ### note: The measures in the file should have been scaled beforehand\n",
    "    # to have zero mean and unit std\n",
    "    \n",
    "    path=db_name+'/'+entry_path+'/'+str(patch_no)+'/'+measure_type\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #print path\n",
    "    #print concept_db[path]\n",
    "    #print concept_db[path][0]\n",
    "    try:\n",
    "        cm=concept_db[path][0]\n",
    "        return cm\n",
    "    except:\n",
    "        print(\"[ERR]: {}, {}, {}, {} with path {}\".format(db_name, entry_path, patch_no, measure_type, path))\n",
    "        return 1.\n",
    "    \n",
    "def get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type=''):\n",
    "    ### note: The measures in the file should have been scaled beforehand\n",
    "    # to have zero mean and unit std\n",
    "    try:\n",
    "        cm = nuclei_concepts[db_name+'/'+entry_path+'/'+str(patch_no)+'/'+measure_type][0]\n",
    "    except:\n",
    "        error_log.write('[get_segmented_concept_measure] {}, {}, {}, {}'.format(db_name, entry_path, patch_no, measure_type))\n",
    "        print \"[ERROR] Issue retreiving concept measure for {}, {}, {}, {}\".format(db_name, entry_path, patch_no, measure_type)\n",
    "        return 1.\n",
    "\n",
    "# BATCH GENERATORS\n",
    "def get_batch_data(patch_list, batch_size=32):\n",
    "    num_samples=len(patch_list)\n",
    "    while True:\n",
    "        offset = 0\n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            batch_contrast=[]\n",
    "            batch_samples=patch_list[offset:offset+batch_size]\n",
    "            for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                patch=data[db_name][entry_path][patch_no]\n",
    "                patch=normalize_patch(patch, normalizer)\n",
    "                patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "                label = get_class(line, entry_path) \n",
    "                batch_x.append(patch)\n",
    "                batch_y.append(label)\n",
    "                # ONES\n",
    "                #batch_ones.append(1.)\n",
    "                # NOISE\n",
    "                #batch_noise.append(np.random.normal(0.))\n",
    "                # CONCEPT = contrast\n",
    "                batch_contrast.append(get_concept_measure(db_name, entry_path, patch_no, measure_type='norm_contrast'))\n",
    "                # CONCEPT = domain\n",
    "                #batch_domain.append(get_domain(db_name, entry_path))\n",
    "                # CONCEPT = nuclei area\n",
    "                #batch_n_area.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='area'))\n",
    "                #batch_contrast.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='area'))\n",
    "                # CONCEPT = nuclei counts\n",
    "                #batch_n_count.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='count'))\n",
    "                #batch_contrast.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='count'))\n",
    "            #batch_domain=keras.utils.to_categorical(batch_domain, num_classes=6)\n",
    "            batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "            batch_cm=np.asarray(batch_contrast, dtype=np.float32) #ones(len(batch_y), dtype=np.float32)\n",
    "            #batch_cm=np.ones(len(batch_y), dtype=np.float32)\n",
    "            yield batch_x, batch_y#, batch_cm\n",
    "            \n",
    "def get_test_batch(patch_list, batch_size=32):\n",
    "    num_samples=len(patch_list)\n",
    "    while True:     \n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            batch_contrast = []\n",
    "            batch_samples=patch_list[offset:offset+batch_size]\n",
    "            for line in batch_samples:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                \n",
    "                patch=data[db_name][entry_path][patch_no]\n",
    "                patch=normalize_patch(patch, normalizer)\n",
    "                patch=keras.applications.inception_v3.preprocess_input(patch)\n",
    "                #patch=keras.applications.resnet50.preprocess_input(patch)\n",
    "                label = get_test_label(entry_path)\n",
    "                #print db_name, entry_path, patch_no, label\n",
    "                batch_x.append(patch)\n",
    "                batch_y.append(label)\n",
    "                #batch_ones.append(1.)\n",
    "                # NOISE\n",
    "                #batch_noise.append(np.random.normal(0.))\n",
    "                # CONCEPT = contrast\n",
    "                batch_contrast.append(get_concept_measure(db_name, entry_path, patch_no, measure_type='norm_contrast'))\n",
    "                # CONCEPT = domain\n",
    "                #batch_domain.append(get_domain(db_name, entry_path))\n",
    "                # CONCEPT = nuclei area\n",
    "                #batch_n_area.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='area'))\n",
    "                #batch_contrast.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='area'))\n",
    "                # CONCEPT = nuclei counts\n",
    "                #batch_n_count.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='count'))\n",
    "                #batch_contrast.append(get_segmented_concept_measure(db_name, entry_path, patch_no, measure_type='count'))\n",
    "            #batch_domain=keras.utils.to_categorical(batch_domain, num_classes=6)\n",
    "            batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "            #batch_cm=np.ones(len(batch_y), dtype=np.float32)\n",
    "            batch_cm=np.asarray(batch_contrast, dtype=np.float32) # np.ones(len(batch_y), dtype=np.float32)\n",
    "            yield batch_x, batch_y#, batch_cm\n",
    "            #yield np.asarray(batch_x, dtype=np.float32), np.asarray(batch_y, dtype=np.float32), np.ones(len(batch_y), dtype=np.float32)#, np.asarray(batch_cm, dtype=np.float32)\n",
    "\n",
    "\n",
    "# In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(d_list, model, batch_size=BATCH_SIZE):\n",
    "    test_generator=get_test_batch(d_list, batch_size=batch_size)\n",
    "    steps=len(d_list)//batch_size\n",
    "    print steps\n",
    "    initial_lr = 1e-4\n",
    "    opt = keras.optimizers.SGD(lr=initial_lr, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=opt, \n",
    "                 loss= [classifier_loss],\n",
    "                   metrics= [my_accuracy])\n",
    "    callbacks = []\n",
    "    y_true=np.zeros(len(d_list))\n",
    "    y_pred=np.zeros((len(d_list),1))\n",
    "    N=0\n",
    "    while N<len(d_list):\n",
    "        x_b, y_b = test_generator.next()\n",
    "        y_p_b = model.predict(x_b)\n",
    "        y_true[N:N+len(y_b)]=y_b\n",
    "        y_pred[N:N+len(y_p_b)]=y_p_b\n",
    "        N+=len(y_p_b)\n",
    "    sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    y_pred_rounded = K.round(sliced_y_pred)\n",
    "    print 'accuracy: ', accuracy_score(y_pred_rounded.eval(session=tf.Session()), y_true)\n",
    "    sliced_y_pred=sliced_y_pred.eval(session=tf.Session())\n",
    "    auc_score=sklearn.metrics.roc_auc_score(y_true,sliced_y_pred)\n",
    "    print 'auc: ', auc_score\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_true=np.reshape(y_true,(len(y_true),1))\n",
    "    for i in range(1):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], sliced_y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), sliced_y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score\n",
    "    plot=False\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    return auc_score, y_pred_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_folder+'/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "accuracy:  0.7019386106623586\n",
      "auc:  0.7870614607595342\n"
     ]
    }
   ],
   "source": [
    "list_=test_list+test2_list\n",
    "auc_score, y_pred_rounded=evaluate_model(list_,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "accuracy:  0.7035541195476576\n",
      "auc:  0.7843508679851962\n",
      "116\n",
      "accuracy:  0.6976305869682283\n",
      "auc:  0.7909975857989268\n",
      "116\n",
      "accuracy:  0.7272482498653743\n",
      "auc:  0.8034849567935647\n",
      "116\n",
      "accuracy:  0.7011308562197092\n",
      "auc:  0.7867221637687483\n",
      "116\n",
      "accuracy:  0.7113624124932687\n",
      "auc:  0.7956770550891037\n",
      "116\n",
      "accuracy:  0.7094776521270867\n",
      "auc:  0.7923959890995591\n",
      "116\n",
      "accuracy:  0.7035541195476576\n",
      "auc:  0.7892464102295357\n",
      "116\n",
      "accuracy:  0.7014001077005924\n",
      "auc:  0.7832763785052101\n",
      "116\n",
      "accuracy:  0.7089391491653204\n",
      "auc:  0.7871577059040785\n",
      "116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a1697bc5a376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_list_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_bootstrap_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_list_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, test_type='bootstrap_overall')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0maucs_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"AUC avg (std): {} ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maucs_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maucs_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-20f3604b2230>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(d_list, model, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0my_p_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-4e6f63710bf5>\u001b[0m in \u001b[0;36mget_test_batch\u001b[0;34m(patch_list, batch_size)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdb_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatch_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mpatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m#patch=keras.applications.resnet50.preprocess_input(patch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9459800835f9>\u001b[0m in \u001b[0;36mnormalize_patch\u001b[0;34m(patch, normalizer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mara/multitask_adversarial/lib/TASK_2_UC1/normalizers.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, I)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_brightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlab_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mnorm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_stds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mnorm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_stds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_means\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/multitask_adversarial/lib/TASK_2_UC1/normalizers.pyc\u001b[0m in \u001b[0;36mget_mean_std\u001b[0;34m(self, I)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \"\"\"\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlab_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeanStdDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mm2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeanStdDev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/multitask_adversarial/lib/TASK_2_UC1/normalizers.pyc\u001b[0m in \u001b[0;36mlab_split\u001b[0;34m(I)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2LAB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mI1\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2.55\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mI2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m128.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_bootstrap_sample(data, n_samples=2):\n",
    "    sample_=[data[i] for i in np.random.choice(len(data),n_samples)]\n",
    "    #sample_=[data[i] for i in range(len(data))]\n",
    "    return sample_\n",
    "\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "model.load_weights(model_folder+'/best_model.h5')\n",
    "aucs_i=[]\n",
    "for i in range(50):\n",
    "    test_list_b=get_bootstrap_sample(list_, n_samples=len(list_))\n",
    "    roc_auc, _=evaluate_model(test_list_b,model)#, test_type='bootstrap_overall')\n",
    "    aucs_i.append(roc_auc)\n",
    "print \"AUC avg (std): {} ({})\".format(np.mean(aucs_i), np.std(aucs_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aucs_i\n",
    "guided_aucs=[0.8097256593007709,\n",
    " 0.8257677583461371,\n",
    " 0.8284987543793056,\n",
    " 0.8123987690905612,\n",
    " 0.8122129193557766,\n",
    " 0.8171528762435989,\n",
    " 0.8203942669480053,\n",
    " 0.801909346122524,\n",
    " 0.8110533838973162,\n",
    " 0.8192357512953368,\n",
    " 0.8163210561918313,\n",
    " 0.8049622015028518,\n",
    " 0.8164248807485958,\n",
    " 0.8261588579545603,\n",
    " 0.8224349505654979,\n",
    " 0.8198083365432877,\n",
    " 0.8233338473508035,\n",
    " 0.8151898394372206,\n",
    " 0.8116935267976655,\n",
    " 0.8230061920156451,\n",
    " 0.80999705999706,\n",
    " 0.8225011543919973,\n",
    " 0.8194816813770406,\n",
    " 0.8124183815864469,\n",
    " 0.8216119126421779,\n",
    " 0.8131742798952575,\n",
    " 0.8133916206624894,\n",
    " 0.8185327317394306,\n",
    " 0.8132800425609821,\n",
    " 0.826003441176462,\n",
    " 0.81668630997849,\n",
    " 0.8185735954190274,\n",
    " 0.8031802696797476,\n",
    " 0.8128920345130592,\n",
    " 0.8152530177337852,\n",
    " 0.8212378998659381,\n",
    " 0.8154698586741791,\n",
    " 0.8117851422186724,\n",
    " 0.8090521202113915,\n",
    " 0.8107352601298298,\n",
    " 0.812407687849384,\n",
    " 0.8090276887279646,\n",
    " 0.8221827009936765,\n",
    " 0.8134452910776464,\n",
    " 0.8137599048373841,\n",
    " 0.8127480241741258,\n",
    " 0.812849532383189,\n",
    " 0.8179884057229148,\n",
    " 0.8306913580318795,\n",
    " 0.8171719576042143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(aucs_i, guided_aucs, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(aucs_i, guided_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(aucs_i, guided_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score, y_pred_rounded=evaluate_model(test_list,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(test2_list,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data_(patch_list, batch_size=32):\n",
    "    print batch_size\n",
    "    num_samples=len(patch_list)\n",
    "    while True:\n",
    "        offset = 0\n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            batch_samples=patch_list[offset:offset+batch_size]\n",
    "            for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                print line\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                patch=data[db_name][entry_path][patch_no]\n",
    "                patch=normalize_patch(patch, normalizer)\n",
    "                patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "                label = get_class(line, entry_path) \n",
    "                batch_x.append(patch)\n",
    "                batch_y.append(label)\n",
    "            batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "            generator_output=[batch_x, batch_y]\n",
    "            \n",
    "            for c in CONCEPT:\n",
    "                batch_concept_values=[]\n",
    "                for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                    #print 'concept: ', c, line\n",
    "                    db_name, entry_path, patch_no = get_keys(line)\n",
    "                    batch_concept_values.append(get_concept_measure(db_name, entry_path, patch_no, measure_type=c))\n",
    "                batch_concept_values=np.asarray(batch_concept_values, dtype=np.float32)\n",
    "                generator_output.append(batch_concept_values)\n",
    "            yield generator_output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCEPT=['ncount', 'narea', 'full_contrast']#, 'domain']\n",
    "error_log=open('./baseline_test_log.txt', 'a')\n",
    "test_generator = get_batch_data_(val_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1820"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_batches=\n",
    "while i <= len(val_list)+32 :\n",
    "    batch = test_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement abc (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for abc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.\u001b[0m\n",
      "Collecting rcvtool\n",
      "  Downloading rcvtool-0.1.5.tar.gz (6.3 kB)\n",
      "Requirement already satisfied: numpy in /home/mara/venv/lib/python2.7/site-packages (from rcvtool) (1.16.6)\n",
      "Requirement already satisfied: opencv-python in /home/mara/venv/lib/python2.7/site-packages (from rcvtool) (4.2.0.32)\n",
      "Requirement already satisfied: scikit-image in /home/mara/venv/lib/python2.7/site-packages (from rcvtool) (0.14.5)\n",
      "Requirement already satisfied: keras in /home/mara/venv/lib/python2.7/site-packages (from rcvtool) (2.2.4)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp27-cp27mu-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 21 kB/s s eta 0:00:012| 208.2 MB 112.5 MB/s eta 0:00:02| 210.5 MB 112.5 MB/s eta 0:00:02��█▏            | 252.1 MB 20.4 MB/s eta 0:00:09\n",
      "\u001b[?25hRequirement already satisfied: statsmodels in /home/mara/venv/lib/python2.7/site-packages (from rcvtool) (0.11.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (2.2.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (1.2.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (6.2.2)\n",
      "Requirement already satisfied: networkx>=1.8 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (2.2)\n",
      "Requirement already satisfied: cloudpickle>=0.2.1 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (1.3.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/mara/venv/lib/python2.7/site-packages (from scikit-image->rcvtool) (1.0.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/mara/venv/lib/python2.7/site-packages (from keras->rcvtool) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/mara/venv/lib/python2.7/site-packages (from keras->rcvtool) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/mara/venv/lib/python2.7/site-packages (from keras->rcvtool) (5.3.1)\n",
      "Requirement already satisfied: h5py in /home/mara/venv/lib/python2.7/site-packages (from keras->rcvtool) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (2.3.2)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (0.2.2)\n",
      "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (1.1.10)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (1.1.0)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (1.0.post1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (0.11.0)\n",
      "Requirement already satisfied: mock>=2.0.0; python_version < \"3\" in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (3.0.5)\n",
      "Requirement already satisfied: functools32>=3.2.3; python_version < \"3\" in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (3.2.3.post2)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.0-py2-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 36.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel; python_version < \"3\" in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (0.36.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (1.12.1)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 84.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/mara/venv/lib/python2.7/site-packages (from tensorflow->rcvtool) (1.34.0)\n",
      "Requirement already satisfied: pandas>=0.21 in /home/mara/venv/lib/python2.7/site-packages (from statsmodels->rcvtool) (0.24.2)\n",
      "Requirement already satisfied: patsy>=0.5 in /home/mara/venv/lib/python2.7/site-packages (from statsmodels->rcvtool) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (2.4.7)\n",
      "Requirement already satisfied: pytz in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (2020.4)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (1.6.1)\n",
      "Requirement already satisfied: subprocess32 in /home/mara/venv/lib/python2.7/site-packages (from matplotlib>=2.0.0->scikit-image->rcvtool) (3.5.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/mara/venv/lib/python2.7/site-packages (from networkx>=1.8->scikit-image->rcvtool) (4.4.2)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /home/mara/venv/lib/python2.7/site-packages (from mock>=2.0.0; python_version < \"3\"->tensorflow->rcvtool) (1.0.2)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 81.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (2.25.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/mara/venv/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (1.0.1)\n",
      "Requirement already satisfied: futures>=3.1.1; python_version < \"3\" in /home/mara/venv/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (3.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mara/venv/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/mara/venv/lib/python2.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (44.1.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<4.6; python_version < \"3.6\"\n",
      "  Downloading rsa-4.5-py2.py3-none-any.whl (36 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/mara/venv/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mara/venv/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (1.26.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<3,>=2.5 in /home/mara/venv/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mara/venv/lib/python2.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow->rcvtool) (2020.12.5)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: rcvtool\n",
      "  Building wheel for rcvtool (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rcvtool: filename=rcvtool-0.1.5-py2-none-any.whl size=8715 sha256=2e46a2761f2e7e1c2012ed2575d5a74de442284c9505c6b38c98cacc9ec3b22f\n",
      "  Stored in directory: /home/mara/.cache/pip/wheels/a0/1f/50/0a34a02215cf95403c129de91c16ca9e87d145dd798a8a9904\n",
      "Successfully built rcvtool\n",
      "Installing collected packages: pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-estimator, tensorflow, rcvtool\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.8.0\n",
      "    Uninstalling tensorboard-1.8.0:\n",
      "      Successfully uninstalled tensorboard-1.8.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 1.8.0 requires tensorboard<1.9.0,>=1.8.0, but you'll have tensorboard 2.1.0 which is incompatible.\n",
      "tensorflow 2.1.0 requires scipy==1.2.2; python_version < \"3\", but you'll have scipy 1.2.3 which is incompatible.\u001b[0m\n",
      "Successfully installed cachetools-3.1.1 google-auth-1.30.1 google-auth-oauthlib-0.4.1 oauthlib-3.1.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rcvtool-0.1.5 requests-oauthlib-1.3.0 rsa-4.5 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named abc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0dcb399177c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'pip install rcvtool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrcvtool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/rcvtool/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrcvtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_color_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_all_color_measures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_texture_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_all_texture_measures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_batch_activations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_rsquared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_rcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrcvtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantize_hue_ranges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround_hue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_picker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhsv_histograms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorfulness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrcvtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexture_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mharalick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/rcvtool/rcv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miolib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/iolib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mforeign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStataReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenfromdta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavetxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv2st\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msmpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_pickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_testing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/iolib/foreign.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m from statsmodels.compat.python import (lzip, lmap, lrange,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                        lfilter, asbytes, asstr)\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalcsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_testing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from .python import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mPY37\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0masunicode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/tools/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_constant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_testing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'add_constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'categorical'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/tools/tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_recarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/tools/validation/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .validation import (array_like, bool_like,  dict_like,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          float_like, int_like, PandasWrapper, string_like)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m __all__ = ['array_like', 'bool_like', 'dict_like', 'float_like', 'int_like',\n",
      "\u001b[0;32m/home/mara/venv/local/lib/python2.7/site-packages/statsmodels/tools/validation/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named abc"
     ]
    }
   ],
   "source": [
    "!pip install rcvtool\n",
    "import rcvtool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rsquared(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    # total sum of squares, TTS\n",
    "    average_y = np.mean(labels)\n",
    "    total_errors = labels - average_y\n",
    "    total_sum_squares = np.sum(np.asarray([pow(total_errors[i],2) for i in range(len(total_errors))]))\n",
    "    #rsquared is 1-RSS/TTS\n",
    "    rss_over_tts =   sum_squared_errors/total_sum_squares\n",
    "    rsquared = 1-rss_over_tts\n",
    "    return rsquared\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_i = compute_rsquared(all_cm_i, all_p_cm_i)\n",
    "mse_i = compute_mse(all_cm_i, all_p_cm_i)\n",
    "print 'Internal: ', r2_i, mse_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_e = compute_rsquared(all_cm_e, all_p_cm_e)\n",
    "mse_e = compute_mse(all_cm_e, all_p_cm_e)\n",
    "print 'External: ', r2_e, mse_e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
