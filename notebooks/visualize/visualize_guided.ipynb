{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "res_folders=os.listdir('../../results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder='/home/mara/multitask_adversarial/results/NCOUNT_822/'\n",
    "CONCEPT=['domain', 'ncount', 'narea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(0)# str(hvd.local_rank())\n",
    "keras.backend.set_session(tf.Session(config=config))\n",
    "verbose=1 \n",
    "init=tf.global_variables_initializer() #initialize_all_variables()\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "## Loading OS libraries to configure server preferences\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import setproctitle\n",
    "SERVER_NAME = 'ultrafast'\n",
    "EXPERIMENT_TYPE='visualize_guided'\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "## Adding PROCESS_UC1 utilities\n",
    "sys.path.append('../../lib/TASK_2_UC1/')\n",
    "from models import *\n",
    "from util import otsu_thresholding\n",
    "from extract_xml import *\n",
    "from functions import *                   \n",
    "sys.path.append('../../lib/')\n",
    "from mlta import *\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(0)# str(hvd.local_rank())\n",
    "keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "verbose=1 \n",
    "\"\"\"loading dataset files\"\"\"\n",
    "#rank = MPI.COMM_WORLD.rank\n",
    "cam16 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/cam16_500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "all500 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/all500/patches.h5py',  'r', libver='latest', swmr=True)\n",
    "extra17 = hd.File('/home/mara/adversarialMICCAI/data/ultrafast/extra17/patches.h5py','r', libver='latest', swmr=True)\n",
    "tumor_extra17=hd.File('/home/mara/adversarialMICCAI/data/ultrafast/1129-1155/patches.h5py', 'r', libver='latest', swmr=True)\n",
    "test2 = hd.File('/mnt/nas2/results/IntermediateResults/Camelyon/ultrafast/test_data2/patches.hdf5', 'r', libver='latest', swmr=True)\n",
    "pannuke= hd.File('/mnt/nas2/results/IntermediateResults/Camelyon/pannuke/patches_fix.hdf5', 'r', libver='latest', swmr=True)\n",
    "\n",
    "global datasetss\n",
    "datasetss={'cam16':cam16,'all500':all500,'extra17':extra17, 'tumor_extra17':tumor_extra17, 'test_data2': test2, 'pannuke':pannuke}\n",
    "\n",
    "global concept_db\n",
    "concept_db = hd.File('../../data/normalized_cmeasures/concept_values_def.h5py','r')\n",
    "#concept_db = hd.File('/mnt/nas2/results/IntermediateResults/Mara/MICCAI2020/MELBA_only_contrast_n.hd','r')\n",
    "#/mnt/nas2/results/IntermediateResults/Mara/MICCAI2020/MELBA_normalized_concepts.hd', 'r')\n",
    "# Note: nuclei_concepts not supported yet\n",
    "#global nuclei_concepts\n",
    "#nuclei_concepts=hd.File('/mnt/nas2/results/IntermediateResults/Mara/MICCAI2020/normalized_nuclei_concepts_db_new_try_def.hdf5','r')\n",
    "\n",
    "\n",
    "# Note: with uncertainty training we do not need CONCEPT ALPHAS (or LAMBDAs?) anymore\n",
    "# We still need to specify the learning rate of the gradient reversal (if we want to change it) or of the additional task.\n",
    "# I think we want to reduce it of a tenth or so\n",
    "\n",
    "#SYSTEM CONFIGS \n",
    "CONFIG_FILE = '../../doc/config.cfg'\n",
    "COLOR = True\n",
    "#global new_folder\n",
    "#new_folder = getFolderName()\n",
    "#folder_name=EXPERIMENT_TYPE\n",
    "#new_folder = 'results/'+folder_name #new_folder\n",
    "#os.mkdir(new_folder)\n",
    "\n",
    "# creating an ERR.log file to keep track of issues happened during model run\n",
    "#global error_log\n",
    "#error_log=open(new_folder+'/ERR.log', 'w')\n",
    "#llg.basicConfig(filename=os.path.join(ne\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# SAVE FOLD\n",
    "f=open(model_folder+\"/seed.txt\",\"r\")\n",
    "seed=1001#int(f.read())\n",
    "if verbose:  print(seed)\n",
    "#f.write(str(seed))\n",
    "f.close()\n",
    "\n",
    "# SET PROCESS TITLE\n",
    "setproctitle.setproctitle('{}'.format(EXPERIMENT_TYPE))\n",
    "\n",
    "# SET SEED\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# DATA SPLIT CSVs \n",
    "train_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/train_shuffle.csv', 'r') # How is the encoding of .csv files ?\n",
    "val_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/val_shuffle.csv', 'r')\n",
    "test_csv=open('/mnt/nas2/results/IntermediateResults/Camelyon/test_shuffle.csv', 'r')\n",
    "train_list=train_csv.readlines()\n",
    "val_list=val_csv.readlines()\n",
    "test_list=test_csv.readlines()\n",
    "test2_csv = open('/mnt/nas2/results/IntermediateResults/Camelyon/test2_shuffle.csv', 'r')\n",
    "test2_list=test2_csv.readlines()\n",
    "test2_csv.close()\n",
    "train_csv.close()\n",
    "val_csv.close()\n",
    "test_csv.close()\n",
    "data_csv=open('../../doc/pannuke_data_shuffle.csv', 'r')\n",
    "data_list=data_csv.readlines()\n",
    "data_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using brightness standardization\n"
     ]
    }
   ],
   "source": [
    "# STAIN NORMALIZATION\n",
    "def get_normalizer(patch, save_folder='../../results/'):\n",
    "    normalizer = ReinhardNormalizer()\n",
    "    normalizer.fit(patch)\n",
    "    np.save('{}/normalizer'.format(save_folder),normalizer)\n",
    "    np.save('{}/normalizing_patch'.format(save_folder), patch)\n",
    "    #print('Normalisers saved to disk.')\n",
    "    return normalizer\n",
    "def normalize_patch(patch, normalizer):\n",
    "    return np.float64(normalizer.transform(np.uint8(patch)))\n",
    "\n",
    "global normalizer\n",
    "db_name, entry_path, patch_no = get_keys(data_list[0])\n",
    "normalization_reference_patch = datasetss[db_name][entry_path][patch_no]\n",
    "normalizer = get_normalizer(normalization_reference_patch, save_folder='../../results/')\n",
    "\n",
    "\"\"\"\n",
    "Batch generators: \n",
    "They load a patch list: a list of file names and paths. \n",
    "They use the list to create a batch of 32 samples. \n",
    "\"\"\"\n",
    "# Retrieve Concept Measures\n",
    "def get_concept_measure(db_name, entry_path, patch_no, measure_type=''):\n",
    "    ### note: The measures in the file should have been scaled beforehand\n",
    "    # to have zero mean and unit std\n",
    "    \n",
    "    path=db_name+'/'+entry_path+'/'+str(patch_no)+'/'+measure_type\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #print path\n",
    "    #print concept_db[path]\n",
    "    #print concept_db[path][0]\n",
    "    try:\n",
    "        cm=concept_db[path][0]\n",
    "        return cm\n",
    "    except:\n",
    "        print(\"[ERR]: {}, {}, {}, {} with path {}\".format(db_name, entry_path, patch_no, measure_type, path))\n",
    "        return 1.\n",
    "    \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, patch_list, concept=CONCEPT, batch_size=32, shuffle=True, data_type=0):\n",
    "        self.batch_size=batch_size\n",
    "        self.patch_list=patch_list\n",
    "        self.shuffle=shuffle\n",
    "        self.concept = concept\n",
    "        self.data_type=data_type\n",
    "        print 'data type:', data_type\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.patch_list)/self.batch_size))\n",
    "    def __getitem__(self, index):\n",
    "        indexes=self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        patch_list_temp=[self.patch_list[k] for k in indexes]\n",
    "        #x, y, cm = self.__data_generation(self, patch_list_temp)\n",
    "        self.patch_list_temp=patch_list_temp\n",
    "        return self.__data_generation(self), None\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.patch_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def __data_generation(self, patch_list_temp):\n",
    "        patch_list_temp=self.patch_list_temp\n",
    "        batch_x=np.zeros((len(patch_list_temp), 224,224,3))\n",
    "        batch_y=np.zeros(len(patch_list_temp))\n",
    "        i=0\n",
    "        for line in patch_list_temp:\n",
    "            db_name, entry_path, patch_no = get_keys(line)\n",
    "            patch=datasetss[db_name][entry_path][patch_no]\n",
    "            patch=normalize_patch(patch, normalizer)\n",
    "            patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "            label = get_class(line, entry_path) \n",
    "            if self.data_type!=0:\n",
    "                label=get_test_label(entry_path)\n",
    "            batch_x[i]=patch\n",
    "            batch_y[i]=label\n",
    "            i+=1\n",
    "        #batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "        #batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "        #return [batch_x, batch_y, np.ones(len(patch_list_temp))], None\n",
    "        generator_output=[batch_x, batch_y]#np.ones(len(patch_list_temp)\n",
    "        for c in self.concept:\n",
    "            batch_concept_values=np.zeros(len(patch_list_temp))\n",
    "            i=0\n",
    "            for line in patch_list_temp:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                #print 'line: {}, cmeasure: '.format(line),get_concept_measure(db_name, entry_path, patch_no, measure_type=c)\n",
    "                batch_concept_values[i]=get_concept_measure(db_name, entry_path, patch_no, measure_type=c)\n",
    "                i+=1\n",
    "            #print 'bcm: ', batch_concept_values\n",
    "            generator_output.append(batch_concept_values)\n",
    "        return generator_output\n",
    "\n",
    "def get_batch_data(patch_list, batch_size=32):\n",
    "    num_samples=len(patch_list)\n",
    "    while True:\n",
    "        offset = 0\n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            #concepts=['full_contrast','full_correlation','narea', 'ncount','nuclei_contrast','nuclei_correlation']\n",
    "            #for c in concepts:\n",
    "            #batch_concept_values[c]=[]\n",
    "            batch_samples=patch_list[offset:offset+batch_size]\n",
    "            for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                patch=datasetss[db_name][entry_path][patch_no]\n",
    "                patch=normalize_patch(patch, normalizer)\n",
    "                patch=keras.applications.inception_v3.preprocess_input(patch) \n",
    "                label = get_class(line, entry_path) \n",
    "                batch_x.append(patch)\n",
    "                batch_y.append(label)\n",
    "            batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "            generator_output=[batch_x, batch_y]\n",
    "            \n",
    "            for c in CONCEPT:\n",
    "                batch_concept_values=[]\n",
    "                for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                    batch_concept_values.append(get_concept_measure(db_name, entry_path, patch_no, measure_type=c))\n",
    "                batch_concept_values=np.asarray(batch_concept_values, dtype=np.float32)\n",
    "                generator_output.append(batch_concept_values)\n",
    "            #batch_domain=keras.utils.to_categorical(batch_domain, num_classes=6)\n",
    "            yield generator_output, None\n",
    "            \n",
    "def get_test_batch(patch_list, batch_size=32):\n",
    "    num_samples=len(patch_list)\n",
    "    while True:     \n",
    "        for offset in range(0,num_samples, batch_size):\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "            #batch_concept_values={}\n",
    "            #concepts=['full_contrast','full_correlation','narea', 'ncount','nuclei_contrast','nuclei_correlation']\n",
    "            #for c in concepts:\n",
    "            #    batch_concept_values[c]=[]\n",
    "            batch_samples=patch_list[offset:offset+batch_size]\n",
    "            for line in batch_samples:\n",
    "                db_name, entry_path, patch_no = get_keys(line)\n",
    "                patch=datasetss[db_name][entry_path][patch_no]\n",
    "                patch=normalize_patch(patch, normalizer)\n",
    "                patch=keras.applications.inception_v3.preprocess_input(patch)\n",
    "                #patch=keras.applications.resnet50.preprocess_input(patch)\n",
    "                label = get_test_label(entry_path)\n",
    "                batch_x.append(patch)\n",
    "                batch_y.append(label)\n",
    "            batch_x=np.asarray(batch_x, dtype=np.float32)\n",
    "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
    "            generator_output=[batch_x, batch_y]\n",
    "            for c in CONCEPT:\n",
    "                batch_concept_values=[]\n",
    "                for line in batch_samples[:(num_samples//batch_size)*batch_size]:\n",
    "                    batch_concept_values.append(get_concept_measure(db_name, entry_path, patch_no, measure_type=c))\n",
    "                batch_concept_values=np.asarray(batch_concept_values, dtype=np.float32)\n",
    "                generator_output.append(batch_concept_values)\n",
    "            yield generator_output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib as mpl   \n",
    "#mpl.use('Agg')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "from keras import *\n",
    "import setproctitle\n",
    "SERVER_NAME = 'ultrafast'\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "## Adding PROCESS_UC1 utilities\n",
    "sys.path.append('../../lib/TASK_2_UC1/')\n",
    "from models import *\n",
    "from util import otsu_thresholding\n",
    "from extract_xml import *\n",
    "from functions import *                   \n",
    "sys.path.append('../../lib/')\n",
    "from mlta import *\n",
    "import math\n",
    "import keras.callbacks as callbacks\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"         \n",
    "Building guidable model \n",
    "\"\"\"\n",
    "def get_baseline_model(hp_lambda=0., domain=False, c_list=[]):\n",
    "    base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "    layers_list=['conv2d_92', 'conv2d_93', 'conv2d_88', 'conv2d_89', 'conv2d_86']\n",
    "    #layers_list=[]\n",
    "    for i in range(len(base_model.layers[:])):\n",
    "        layer=base_model.layers[i]\n",
    "        if layer.name in layers_list:\n",
    "            print layer.name\n",
    "            layer.trainable=True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    feature_output=base_model.layers[-1].output\n",
    "    gap_layer_output = keras.layers.GlobalAveragePooling2D()(feature_output)\n",
    "    feature_output = Dense(2048, activation='relu', name='finetuned_features1',kernel_regularizer=keras.regularizers.l2(0.01))(gap_layer_output) \n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(512, activation='relu', name='finetuned_features2',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    feature_output = Dense(256, activation='relu', name='finetuned_features3',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "    feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "    grl_layer=GradientReversal(hp_lambda=hp_lambda)\n",
    "    feature_output_grl = grl_layer(feature_output)\n",
    "    if domain:\n",
    "        domain_adversarial = keras.layers.Dense(7, activation = keras.layers.Activation('softmax'), name='domain_adversarial')(feature_output_grl)\n",
    "    finetuning = Dense(1,name='predictions')(feature_output)\n",
    "    ## here you need to check how many other concepts you have apart from domain adversarial\n",
    "    # then you add one layer per each. \n",
    "    if domain:\n",
    "        output_nodes=[finetuning, domain_adversarial]\n",
    "    else: \n",
    "        output_nodes=[finetuning]\n",
    "    for c in c_list:\n",
    "        if c!='domain':\n",
    "            concept_layer=  keras.layers.Dense(1, activation = keras.layers.Activation('linear'), name='extra_{}'.format(c.strip(' ')))(feature_output)\n",
    "            output_nodes.append(concept_layer)\n",
    "    model = Model(input=base_model.input, output=output_nodes)\n",
    "    model.grl_layer=grl_layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_88\n",
      "conv2d_89\n",
      "conv2d_92\n",
      "conv2d_93\n",
      "conv2d_86\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "layers_list=['conv2d_92', 'conv2d_93', 'conv2d_88', 'conv2d_89', 'conv2d_86']\n",
    "#layers_list=[]\n",
    "for i in range(len(base_model.layers[:])):\n",
    "    layer=base_model.layers[i]\n",
    "    if layer.name in layers_list:\n",
    "        print layer.name\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "feature_output=base_model.layers[-1].output\n",
    "gap_layer_output = keras.layers.GlobalAveragePooling2D()(feature_output)\n",
    "feature_output = keras.layers.Dense(2048, activation='relu', name='finetuned_features1',kernel_regularizer=keras.regularizers.l2(0.01))(gap_layer_output) \n",
    "feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "feature_output = keras.layers.Dense(512, activation='relu', name='finetuned_features2',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "feature_output = keras.layers.Dense(256, activation='relu', name='finetuned_features3',kernel_regularizer=keras.regularizers.l2(0.01))(feature_output)\n",
    "feature_output = keras.layers.Dropout(0.8, noise_shape=None, seed=None)(feature_output)\n",
    "finetuning = keras.layers.Dense(1,name='predictions')(feature_output)\n",
    "regression_output = keras.layers.Dense(1, activation = keras.layers.Activation('linear'), name='concept_regressor')(gap_layer_output)\n",
    "model = keras.Model(input=base_model.input, output=[finetuning, regression_output])\n",
    "# Callbacks\n",
    "def compute_mse(labels, predictions):\n",
    "    errors = labels - predictions\n",
    "    sum_squared_errors = np.sum(np.asarray([pow(errors[i],2) for i in range(len(errors))]))\n",
    "    mse = sum_squared_errors / len(labels)\n",
    "    return mse\n",
    "class eval_model(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        f = open('{}/val_by_epoch.txt'.format(new_folder), 'a')\n",
    "        pred_ = self.model.predict_generator(val_generator2, steps = len(val_list)// BATCH_SIZE, workers=4, use_multiprocessing=False)#// hvd.size()) \n",
    "        #import pdb; pdb.set_trace()\n",
    "        y_true = pred_[:,0]\n",
    "        y_pred = pred_[:,2]\n",
    "        print 'y_true: ', y_true\n",
    "        print 'y_pred: ', y_pred\n",
    "        val_acc = my_accuracy_np(y_true, y_pred)\n",
    "        cm_true = pred_[:, 1]\n",
    "        cm_pred = pred_[:,3]\n",
    "        print 'cm_true: ', cm_true\n",
    "        print 'cm_pred: ', cm_pred\n",
    "        \n",
    "        val_r2 = r_square_np(cm_true, cm_pred)\n",
    "        val_mse = compute_mse(cm_true, cm_pred)\n",
    "        print(\"Val acc: {}, r2: {}, MSE: {}\".format(val_acc, val_r2, val_mse))\n",
    "        report_val_acc.append(val_acc)\n",
    "        report_val_r2.append(val_r2)\n",
    "        report_val_mse.append(val_mse)\n",
    "        f.write(\"Val acc: {}, r2: {}, mse: {}\".format(val_acc, val_r2, val_mse))\n",
    "        \n",
    "        train_pred_ = self.model.predict_generator(train_generator2, steps=100, workers=1, use_multiprocessing=False)\n",
    "        cm_true = train_pred_[:, 1]\n",
    "        cm_pred = train_pred_[:,3]\n",
    "        print 'train_cmtrue: ', cm_true\n",
    "        print 'train_cmpred: ', cm_pred\n",
    "        train_r2 = r_square_np(cm_true, cm_pred)\n",
    "        train_mse = compute_mse(cm_true, cm_pred)\n",
    "        print(\"Train r2: {}, MSE: {}\".format(train_r2, train_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END Callbacks\n",
    "#\n",
    "def keras_mse(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.keras.losses.mean_squared_error(y_true, y_pred))\n",
    "    #return tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def bbce(y_true, y_pred):\n",
    "    # we use zero weights to set the loss to zero for unlabeled data\n",
    "    verbose=0\n",
    "    zero= tf.constant(-1, dtype=tf.float32)\n",
    "    where = tf.not_equal(y_true, zero)\n",
    "    where = tf.reshape(where, [-1])\n",
    "    indices=tf.where(where) #indices where the item of y_true is NOT -1\n",
    "    indices = tf.reshape(indices, [-1])\n",
    "    sliced_y_true = tf.nn.embedding_lookup(y_true, indices)\n",
    "    sliced_y_pred = tf.nn.embedding_lookup(y_pred, indices)\n",
    "    n1 = tf.shape(indices)[0] #number of train images in batch\n",
    "    batch_size = tf.shape(y_true)[0]\n",
    "    n2 = batch_size - n1 #number of test images in batch\n",
    "    sliced_y_true = tf.reshape(sliced_y_true, [n1, -1])\n",
    "    n1_ = tf.cast(n1, tf.float32)\n",
    "    n2_ = tf.cast(n2, tf.float32)\n",
    "    multiplier = (n1_+ n2_) / n1_\n",
    "    zero_class = tf.constant(0, dtype=tf.float32)\n",
    "    where_class_is_zero=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, zero_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_zero=tf.Print(where_class_is_zero,[where_class_is_zero],'where_class_is_zero: ')\n",
    "    class_weight_zero = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_zero, dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    \n",
    "    if verbose:\n",
    "        class_weight_zero=tf.Print(class_weight_zero,[class_weight_zero],'class_weight_zero: ')\n",
    "    one_class = tf.constant(1, dtype=tf.float32)\n",
    "    where_class_is_one=tf.cast(tf.reduce_sum(tf.cast(tf.equal(sliced_y_true, one_class), dtype=tf.float32)), dtype=tf.float32)\n",
    "    if verbose:\n",
    "        where_class_is_one=tf.Print(where_class_is_one,[where_class_is_one],'where_class_is_one: ')\n",
    "        n1_=tf.Print(n1_,[n1_],'n1_: ')\n",
    "    class_weight_one = tf.cast(tf.divide(n1_, 2. * tf.cast(where_class_is_one,dtype=tf.float32)+0.001), dtype=tf.float32)\n",
    "    class_weight_zero =  tf.constant(23477.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    class_weight_one =  tf.constant(123820.0/(23477.0+123820.0), dtype=tf.float32)\n",
    "    A = tf.ones(tf.shape(sliced_y_true), dtype=tf.float32) - sliced_y_true \n",
    "    A = tf.scalar_mul(class_weight_zero, A)\n",
    "    B = tf.scalar_mul(class_weight_one, sliced_y_true) \n",
    "    class_weight_vector=A+B\n",
    "    ce = tf.nn.sigmoid_cross_entropy_with_logits(labels=sliced_y_true,logits=sliced_y_pred)\n",
    "    ce = tf.multiply(class_weight_vector,ce)\n",
    "    return tf.reduce_mean(ce)\n",
    "\n",
    "# Custom loss layer\n",
    "from keras.initializers import Constant\n",
    "class CustomMultiLossLayer(Layer):\n",
    "    def __init__(self, nb_outputs=2, **kwargs):\n",
    "        self.nb_outputs = nb_outputs\n",
    "        self.is_placeholder = True\n",
    "        super(CustomMultiLossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape=None):\n",
    "        self.log_vars = []\n",
    "        for i in range(self.nb_outputs):\n",
    "            self.log_vars += [self.add_weight(name='log_var' + str(i), shape=(1,), initializer=Constant(0.), trainable=True)]\n",
    "        super(CustomMultiLossLayer, self).build(input_shape)\n",
    "    \n",
    "    def multi_loss(self,  ys_true, ys_pred):\n",
    "        #print len(ys_true)\n",
    "        assert len(ys_true) == self.nb_outputs and len(ys_pred) == self.nb_outputs\n",
    "        loss = 0\n",
    "        i=0\n",
    "        for y_true, y_pred, log_var in zip(ys_true, ys_pred, self.log_vars):\n",
    "            precision =K.exp(-log_var[0]) ###MODIFICATION HERE\n",
    "            if i==0:\n",
    "                pred_loss = bbce(y_true, y_pred)\n",
    "                term = precision*pred_loss + 0.5 * log_var[0]  \n",
    "                #term=tf.Print(term, [term], 'bbce: ')\n",
    "            else:\n",
    "                pred_loss = keras_mse(y_true, y_pred)\n",
    "                #pred_loss=tf.Print(pred_loss, [pred_loss], 'MSE: ')\n",
    "                term = 0.5 * precision * pred_loss + 0.5 * log_var[0]\n",
    "                #term=tf.Print(term, [term], 'MSE: ')\n",
    "            loss+=term\n",
    "            term = 0.\n",
    "            i+=1\n",
    "        return K.mean(loss)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        ys_true = inputs[:self.nb_outputs]\n",
    "        ys_pred = inputs[self.nb_outputs:]\n",
    "        loss = self.multi_loss(ys_true, ys_pred)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return K.concatenate(inputs, -1)\n",
    "def get_trainable_model(baseline_model):\n",
    "    inp = keras.layers.Input(shape=(224,224,3,), name='inp')\n",
    "    y1_pred, y2_pred = baseline_model(inp)\n",
    "    y1_true=keras.layers.Input(shape=(1,),name='y1_true')\n",
    "    y2_true=keras.layers.Input(shape=(1,),name='y2_true')\n",
    "    out = CustomMultiLossLayer(nb_outputs=2)([y1_true, y2_true, y1_pred, y2_pred])\n",
    "    return Model(input=[inp, y1_true, y2_true], output=out)\n",
    "\n",
    "\"\"\" Get trainable model with Hepistemic Uncertainty Weighted Loss \"\"\"\n",
    "t_m = get_trainable_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting baseline model \n",
    "baseline_ref = get_baseline_model(hp_lambda=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 111, 111, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 111, 111, 32) 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 111, 111, 32) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 109, 109, 32) 9216        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 109, 109, 32) 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 109, 109, 32) 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 109, 109, 64) 18432       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 109, 109, 64) 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 109, 109, 64) 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 54, 54, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 54, 54, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 52, 52, 192)  138240      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 52, 52, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 52, 52, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 25, 25, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 25, 25, 96)   55296       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 25, 25, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 25, 25, 64)   76800       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 25, 25, 96)   82944       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 25, 25, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 25, 25, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 25, 25, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_101[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 25, 25, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 25, 25, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 25, 25, 96)   55296       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 25, 25, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 25, 25, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 25, 25, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 25, 25, 64)   76800       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 25, 25, 96)   82944       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 25, 25, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 25, 25, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 25, 25, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 25, 25, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 25, 25, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 25, 25, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_108[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 25, 25, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 25, 25, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 25, 25, 96)   55296       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 25, 25, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 25, 25, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 25, 25, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 25, 25, 64)   76800       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 25, 96)   82944       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 25, 25, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 25, 25, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 25, 25, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 25, 25, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 25, 25, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 25, 25, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 25, 25, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_115[0][0]             \n",
      "                                                                 activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 25, 25, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 25, 25, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 25, 25, 96)   55296       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 25, 25, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 25, 25, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 96)   82944       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 12, 12, 384)  1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 96)   288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 12, 12, 384)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 96)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_122[0][0]             \n",
      "                                                                 activation_125[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 128)  114688      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 128)  114688      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 128)  384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 128)  384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 192)  172032      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 192)  172032      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_126[0][0]             \n",
      "                                                                 activation_129[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 160)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 160)  179200      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 160)  179200      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 160)  480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 192)  576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 192)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "                                                                 activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 160)  179200      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 160)  179200      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 160)  480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 160)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 192)  215040      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 192)  215040      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_146[0][0]             \n",
      "                                                                 activation_149[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 192)  258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 12, 12, 192)  258048      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_156[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "                                                                 activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 12, 12, 192)  258048      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 12, 12, 192)  576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 12, 12, 192)  576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 12, 12, 192)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 12, 12, 192)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 5, 5, 320)    552960      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 192)    331776      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 5, 5, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 5, 5, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_167[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 384)    1548288     activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 384)    442368      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 384)    442368      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_174[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_178[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_172[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 384)    1548288     activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 384)    442368      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 384)    442368      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 5, 5, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_183[0][0]             \n",
      "                                                                 activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_187[0][0]             \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_181[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features1 (Dense)     (None, 2048)         4196352     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2048)         0           finetuned_features1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features2 (Dense)     (None, 512)          1049088     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           finetuned_features2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "finetuned_features3 (Dense)     (None, 256)          131328      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256)          0           finetuned_features3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1)            257         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,179,809\n",
      "Trainable params: 5,377,025\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_ref.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(input_model, image, layer_name,H=224,W=224):\n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.get_layer('predictions').output#[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.get_layer('input_1').input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "    #print (cam)\n",
    "\n",
    "    cam = np.maximum(cam, 0) # equivalent to RELU pass\n",
    "    cam = cv2.resize(cam, (H, W))\n",
    "    #cam = resize(cam, (H, W))\n",
    "    # cam = zoom(cam,H/cam.shape[0])\n",
    "    #cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_baseline(input_model, image, layer_name,H=224,W=224):\n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.get_layer('predictions').output#[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.get_layer('input_2').input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "    #print (cam)\n",
    "\n",
    "    cam = np.maximum(cam, 0) # equivalent to RELU pass\n",
    "    cam = cv2.resize(cam, (H, W))\n",
    "    #cam = resize(cam, (H, W))\n",
    "    # cam = zoom(cam,H/cam.shape[0])\n",
    "    #cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_concept(input_model, image, layer_name,H=224,W=224):\n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = input_model.get_layer('concept_regressor').output#[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    grads = normalize(grads)\n",
    "    gradient_function = K.function([input_model.get_layer('input_1').input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    cam = np.dot(output, weights)\n",
    "    #print (cam)\n",
    "\n",
    "    cam = np.maximum(cam, 0) # equivalent to RELU pass\n",
    "    cam = cv2.resize(cam, (H, W))\n",
    "    #cam = resize(cam, (H, W))\n",
    "    # cam = zoom(cam,H/cam.shape[0])\n",
    "    #cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer() #initialize_all_variables()\n",
    "sess=tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_m = get_trainable_model(model)\n",
    "t_m.load_weights(model_folder+'/best_model.h5')x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator_=get_test_batch(test_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n",
      "[ERR]: all500, normal/level7/centre3/patient068/node1/patches, 148, domain with path all500/normal/level7/centre3/patient068/node1/patches/148/domain\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4fd1e8d0ce7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_generator_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "test_generator_=get_test_batch(test_list, batch_size=32)\n",
    "[x_b, y_b, cm_b], _ = test_generator_.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_ref.load_weights('../../results/BASEL/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap=grad_cam(model, np.expand_dims(x_b[0], 0), 'mixed10')\n",
    "heatmap_ref = grad_cam_baseline(baseline_ref, np.expand_dims(x_b[0],0), 'mixed10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def evaluate_model(d_list, model, batch_size=BATCH_SIZE, test_type=''):\n",
    "    batch_size=32\n",
    "    #d_list=test_list[:100]\n",
    "    #t_gen=DataGenerator(d_list, concept=CONCEPT, batch_size=BATCH_SIZE, data_type=0)\n",
    "    test_generator_=get_test_batch(d_list, batch_size=batch_size)\n",
    "    steps=len(d_list)//batch_size\n",
    "    print steps\n",
    "    initial_lr = 1e-4\n",
    "    opt = keras.optimizers.SGD(lr=initial_lr, momentum=0.9, nesterov=True)\n",
    "    compile_model(t_m,opt,loss=None,metrics=None)\n",
    "    callbacks = []\n",
    "    y_true=np.zeros(len(d_list))\n",
    "    y_pred=np.zeros((len(d_list),1))\n",
    "    N=0\n",
    "    all_cm=np.zeros(len(d_list))\n",
    "    all_p_cm=np.zeros(len(d_list))\n",
    "\n",
    "    while N<len(d_list):\n",
    "        #x_b, y_b, cm_b = t_gen.__getitem__(N)\n",
    "        [x_b, y_b, cm_b], _ = test_generator_.next()\n",
    "        pred_ = t_m.predict([x_b, y_b, cm_b])\n",
    "        y_p_b = pred_[:,2]\n",
    "        cm_p_b = pred_[:,3]\n",
    "\n",
    "        y_true[N:N+len(y_b)]=y_b.reshape(len(y_b))\n",
    "        y_pred[N:N+len(y_p_b)]=y_p_b.reshape(len(y_p_b),1)\n",
    "        all_p_cm[N:N+len(cm_p_b)]=cm_p_b.reshape(len(cm_p_b))\n",
    "        all_cm[N:N+len(cm_b)]=cm_b\n",
    "        N+=len(y_p_b)\n",
    "    y_true=y_true.reshape((len(d_list),1))\n",
    "    acc = my_accuracy(y_true, y_pred).eval(session=tf.Session())\n",
    "    sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    y_pred_rounded = K.round(sliced_y_pred)\n",
    "    acc_sc = accuracy_score(y_pred_rounded.eval(session=tf.Session()), y_true)\n",
    "    print('accuracy: ', acc_sc)\n",
    "    \n",
    "    y_pred = sliced_y_pred.eval(session=tf.Session())\n",
    "    #sliced_y_pred = tf.sigmoid(y_pred)\n",
    "    #y_pred_rounded = K.round(sliced_y_pred)\n",
    "    auc_score=sklearn.metrics.roc_auc_score(y_true,sliced_y_pred.eval(session=tf.Session()))\n",
    "    \n",
    "    '''   fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(1):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example AUC = {}'.format(roc_auc[0]))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()'''    \n",
    "    print 'auc: {}'.format(auc_score)\n",
    "    #auc_record = open('{}/auc_{}.txt'.format(model_folder,test_type), 'w')\n",
    "    #auc_record.write('{}'.format(roc_auc[0]))\n",
    "    #auc_record.close()\n",
    "    return all_cm, all_p_cm, auc_score\n",
    "all_cm_t, all_p_cm_t, roc_auc=evaluate_model(test_list[:],t_m, test_type='internal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(13,17)\n",
    "for i in range(1, len(x_b)):\n",
    "    print i\n",
    "    heatmap=grad_cam(model, np.expand_dims(x_b[i], 0), 'mixed10')\n",
    "    heatmap_concept=grad_cam_concept(model, np.expand_dims(x_b[i], 0), 'mixed10')\n",
    "    heatmap_ref = grad_cam_baseline(baseline_ref, np.expand_dims(x_b[i],0), 'mixed10')\n",
    "    plt.figure()\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(x_b[i])\n",
    "    plt.title('orig')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(x_b[i])\n",
    "    plt.title('guided MT')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(heatmap, alpha=0.7)\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(x_b[i])\n",
    "    plt.imshow(heatmap_concept, alpha=0.7)\n",
    "    plt.title('{}'.format(CONCEPT))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(x_b[i])\n",
    "    plt.imshow(heatmap_ref, alpha=0.7)\n",
    "    plt.title('baseline MT')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./guided/{}_{}'.format(CONCEPT,i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
